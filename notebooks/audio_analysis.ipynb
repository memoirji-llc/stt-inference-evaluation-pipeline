{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Quality Analysis - Batch Processing\n",
    "\n",
    "**Goal:** Calculate audio quality metrics for ALL VHP files to identify audio issues and guide preprocessing decisions.\n",
    "\n",
    "**Output:** DataFrame with per-file metrics + detected issues â†’ saved as `audio_quality_analysis.parquet`\n",
    "\n",
    "**Metrics:**\n",
    "- SNR (signal-to-noise ratio)\n",
    "- Spectral roll-off (bandwidth indicator)\n",
    "- Spectral centroid (brightness)\n",
    "- Spectral flatness (tonal vs noisy)\n",
    "- ZCR (zero crossing rate - noisiness)\n",
    "- Loudness (LUFS)\n",
    "\n",
    "**Issue Detection:**\n",
    "- `bandwidth_limited`: Roll-off < 1000 Hz (missing high frequencies)\n",
    "- `high_noise`: ZCR > 0.05 or SNR < 15 dB\n",
    "- `low_frequency_rumble`: High energy below 80 Hz\n",
    "- `low_loudness`: LUFS < -30 dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pyloudnorm as pyln\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Azure blob utilities\n",
    "from scripts.cloud.azure_utils import list_blobs, download_blob_to_memory\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../credentials/creds.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Azure authentication environment variables\n",
    "import os\n",
    "\n",
    "print(\"Azure Authentication Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"AZURE_STORAGE_ACCOUNT: {os.getenv('AZURE_STORAGE_ACCOUNT')}\")\n",
    "print(f\"AZURE_STORAGE_CONTAINER: {os.getenv('AZURE_STORAGE_CONTAINER')}\")\n",
    "print(f\"AZURE_AUTH: {os.getenv('AZURE_AUTH')}\")\n",
    "print(f\"Connection string set: {'Yes' if os.getenv('AZURE_STORAGE_CONNECTION_STRING') else 'No'}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if all required vars are set\n",
    "required_vars = ['AZURE_STORAGE_ACCOUNT', 'AZURE_STORAGE_CONTAINER', 'AZURE_AUTH']\n",
    "missing = [v for v in required_vars if not os.getenv(v)]\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\nâš ï¸  WARNING: Missing environment variables: {', '.join(missing)}\")\n",
    "    print(\"Please set these before running the notebook:\")\n",
    "    print(\"  export AZURE_STORAGE_ACCOUNT=stgamiadata26828\")\n",
    "    print(\"  export AZURE_STORAGE_CONTAINER=audio-raw\")\n",
    "    print(\"  export AZURE_AUTH=connection_string\")\n",
    "    print(\"  export AZURE_STORAGE_CONNECTION_STRING='...'\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All required environment variables are set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Audio Quality Metric Functions\n",
    "\n",
    "Functions to calculate audio quality metrics from waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_cal(wv, sr) -> np.float32:\n",
    "    \"\"\"Calculate Signal-to-Noise Ratio (dB)\"\"\"\n",
    "    rms_full = librosa.feature.rms(y=wv)\n",
    "    noise_rms = np.mean(rms_full[:, :int(0.5*sr/512)])\n",
    "    signal_rms = np.mean(rms_full)\n",
    "    snr_db = 20 * np.log10(signal_rms / noise_rms)\n",
    "    return snr_db\n",
    "\n",
    "def spectral_rolloff_cal(wv, sr) -> np.float64:\n",
    "    \"\"\"Calculate spectral roll-off (85th percentile frequency)\"\"\"\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=wv, sr=sr, roll_percent=0.85)\n",
    "    return np.median(rolloff)\n",
    "\n",
    "def spectral_flatness_cal(wv) -> np.float64:\n",
    "    \"\"\"Calculate spectral flatness (0=tonal, 1=noisy)\"\"\"\n",
    "    flatness = librosa.feature.spectral_flatness(y=wv)\n",
    "    return np.mean(flatness)\n",
    "\n",
    "def spectral_centroid_cal(wv, sr) -> np.float64:\n",
    "    \"\"\"Calculate spectral centroid (brightness)\"\"\"\n",
    "    centroid = librosa.feature.spectral_centroid(y=wv, sr=sr)\n",
    "    return np.median(centroid)\n",
    "\n",
    "def zcr_cal(wv):\n",
    "    \"\"\"Calculate zero crossing rate (mean and variance)\"\"\"\n",
    "    zcr = librosa.feature.zero_crossing_rate(wv)\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    zcr_var = np.var(zcr)\n",
    "    return zcr_mean, zcr_var\n",
    "\n",
    "def loudness_cal(wv, sr) -> np.float64:\n",
    "    \"\"\"Calculate loudness (LUFS - ITU-R BS.1770-4)\"\"\"\n",
    "    meter = pyln.Meter(sr)\n",
    "    loudness = meter.integrated_loudness(wv)\n",
    "    return loudness\n",
    "\n",
    "def low_frequency_energy(wv, sr, cutoff_hz=80) -> np.float64:\n",
    "    \"\"\"Calculate energy below cutoff frequency (for rumble detection)\"\"\"\n",
    "    # Compute STFT\n",
    "    D = np.abs(librosa.stft(wv))\n",
    "    freqs = librosa.fft_frequencies(sr=sr)\n",
    "    \n",
    "    # Energy below cutoff\n",
    "    low_freq_mask = freqs < cutoff_hz\n",
    "    low_energy = np.sum(D[low_freq_mask, :])\n",
    "    total_energy = np.sum(D)\n",
    "    \n",
    "    # Return ratio\n",
    "    return low_energy / total_energy if total_energy > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Batch Audio Analysis Function\n",
    "\n",
    "Process one audio file and return metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_file(audio_bytes, audio_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze audio file and return quality metrics.\n",
    "    \n",
    "    Handles both audio (MP3, WAV) and video (MP4) files using pydub.\n",
    "    \n",
    "    Args:\n",
    "        audio_bytes: Audio/video file as bytes\n",
    "        audio_id: Identifier for the audio file\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with audio_id and quality metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use pydub to load audio (handles MP3, MP4, M4A, WAV, etc.)\n",
    "        # This extracts audio stream from video files like MP4\n",
    "        audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))\n",
    "        \n",
    "        # Convert to mono and 16kHz (consistent with pipeline)\n",
    "        audio_segment = audio_segment.set_channels(1)\n",
    "        audio_segment = audio_segment.set_frame_rate(16000)\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        samples = np.array(audio_segment.get_array_of_samples())\n",
    "        \n",
    "        # Normalize to float32 [-1, 1]\n",
    "        if audio_segment.sample_width == 2:  # 16-bit\n",
    "            wv = samples.astype(np.float32) / 32768.0\n",
    "        elif audio_segment.sample_width == 4:  # 32-bit\n",
    "            wv = samples.astype(np.float32) / 2147483648.0\n",
    "        else:\n",
    "            wv = samples.astype(np.float32)\n",
    "        \n",
    "        sr = 16000  # Sample rate after conversion\n",
    "        \n",
    "        # Calculate metrics\n",
    "        snr = float(snr_cal(wv, sr))\n",
    "        rolloff = float(spectral_rolloff_cal(wv, sr))\n",
    "        flatness = float(spectral_flatness_cal(wv))\n",
    "        centroid = float(spectral_centroid_cal(wv, sr))\n",
    "        zcr_mean, zcr_var = zcr_cal(wv)\n",
    "        zcr_mean = float(zcr_mean)\n",
    "        zcr_var = float(zcr_var)\n",
    "        loudness = float(loudness_cal(wv, sr))\n",
    "        low_freq_energy_ratio = float(low_frequency_energy(wv, sr, cutoff_hz=80))\n",
    "        \n",
    "        # Duration\n",
    "        duration_sec = len(wv) / sr\n",
    "        \n",
    "        return {\n",
    "            'audio_id': audio_id,\n",
    "            'sample_rate': sr,\n",
    "            'duration_sec': duration_sec,\n",
    "            'snr_db': snr,\n",
    "            'spectral_rolloff_hz': rolloff,\n",
    "            'spectral_flatness': flatness,\n",
    "            'spectral_centroid_hz': centroid,\n",
    "            'zcr_mean': zcr_mean,\n",
    "            'zcr_var': zcr_var,\n",
    "            'loudness_lufs': loudness,\n",
    "            'low_freq_energy_ratio': low_freq_energy_ratio,\n",
    "            'status': 'success'\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'audio_id': audio_id,\n",
    "            'status': 'error',\n",
    "            'error_message': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Issue Detection Logic\n",
    "\n",
    "Detect audio issues based on metric thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_audio_issues(row: pd.Series) -> list:\n",
    "    \"\"\"\n",
    "    Detect audio issues based on quality metrics.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with audio metrics\n",
    "    \n",
    "    Returns:\n",
    "        List of detected issues\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    if row['status'] != 'success':\n",
    "        return issues\n",
    "    \n",
    "    # 1. Bandwidth-limited (lacking high frequencies)\n",
    "    if row['spectral_rolloff_hz'] < 1000:\n",
    "        issues.append('bandwidth_limited_severe')\n",
    "    elif row['spectral_rolloff_hz'] < 4000:\n",
    "        issues.append('bandwidth_limited_moderate')\n",
    "    \n",
    "    # 2. High noise\n",
    "    if row['zcr_mean'] > 0.05:\n",
    "        issues.append('high_noise_zcr')\n",
    "    if row['snr_db'] < 15:\n",
    "        issues.append('high_noise_snr')\n",
    "    \n",
    "    # 3. Low-frequency rumble\n",
    "    if row['low_freq_energy_ratio'] > 0.15:\n",
    "        issues.append('low_frequency_rumble')\n",
    "    \n",
    "    # 4. Low loudness\n",
    "    if row['loudness_lufs'] < -30:\n",
    "        issues.append('low_loudness')\n",
    "    \n",
    "    # 5. Very flat spectrum\n",
    "    if row['spectral_flatness'] > 0.8:\n",
    "        issues.append('very_flat_spectrum')\n",
    "    \n",
    "    return issues\n",
    "\n",
    "\n",
    "def recommend_preprocessing(issues: list) -> list:\n",
    "    \"\"\"\n",
    "    Recommend preprocessing methods based on detected issues.\n",
    "    \n",
    "    Args:\n",
    "        issues: List of detected issues\n",
    "    \n",
    "    Returns:\n",
    "        List of recommended preprocessing methods\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # Always normalize loudness\n",
    "    recommendations.append('loudness_normalization')\n",
    "    \n",
    "    # Bandwidth-limited â†’ EQ boost high frequencies\n",
    "    if 'bandwidth_limited_severe' in issues or 'bandwidth_limited_moderate' in issues:\n",
    "        recommendations.append('eq_high_freq_boost')\n",
    "    \n",
    "    # High noise â†’ Noise reduction\n",
    "    if 'high_noise_zcr' in issues or 'high_noise_snr' in issues:\n",
    "        recommendations.append('noise_reduction')\n",
    "    \n",
    "    # Low-frequency rumble â†’ High-pass filter\n",
    "    if 'low_frequency_rumble' in issues:\n",
    "        recommendations.append('highpass_filter')\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Process All VHP Audio Files\n",
    "\n",
    "Download from Azure Blob and analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all audio/video blobs from Azure\n",
    "blob_prefix = \"loc_vhp/\"  # Updated to match your actual blob structure\n",
    "\n",
    "print(f\"Listing blobs with prefix: {blob_prefix}\")\n",
    "audio_blobs = list_blobs(blob_prefix)\n",
    "\n",
    "# Filter for audio AND video files (pipeline handles both MP3 and MP4)\n",
    "media_extensions = ('.mp3', '.mp4', '.wav', '.m4a', '.flac', '.ogg')\n",
    "audio_blobs = [b for b in audio_blobs if b.lower().endswith(media_extensions)]\n",
    "\n",
    "print(f\"Found {len(audio_blobs)} media files (audio + video)\")\n",
    "print(f\"\\nFirst 5 files:\")\n",
    "for blob in audio_blobs[:5]:\n",
    "    print(f\"  - {blob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING: Limit to small sample for quick testing\n",
    "# Comment out this line once you've verified everything works\n",
    "SAMPLE_SIZE = 3  # Process only first 3 files for testing\n",
    "audio_blobs = audio_blobs[:SAMPLE_SIZE]\n",
    "print(f\"\\nðŸ§ª TEST MODE: Processing only first {SAMPLE_SIZE} files\")\n",
    "print(\"Once verified, comment out the SAMPLE_SIZE lines above to process all files\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all audio files (streaming - one at a time)\n",
    "# Only stores metrics, not audio data\n",
    "results = []\n",
    "\n",
    "print(f\"\\nProcessing {len(audio_blobs)} audio files (streaming)...\\n\")\n",
    "print(\"Memory usage: Only stores metrics (~2-3 KB per file), not audio\\n\")\n",
    "\n",
    "for blob_path in tqdm(audio_blobs):\n",
    "    audio_id = Path(blob_path).stem\n",
    "    \n",
    "    try:\n",
    "        # Download ONE file, analyze, discard audio, keep metrics\n",
    "        audio_bytes = download_blob_to_memory(blob_path)\n",
    "        result = analyze_audio_file(audio_bytes, audio_id)\n",
    "        results.append(result)  # Only stores ~12 numbers per file\n",
    "        \n",
    "        # audio_bytes is garbage collected after this iteration\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {blob_path}: {e}\")\n",
    "        results.append({\n",
    "            'audio_id': audio_id,\n",
    "            'status': 'error',\n",
    "            'error_message': str(e)\n",
    "        })\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} files\")\n",
    "print(f\"Memory used for results: ~{len(results) * 0.3:.1f} KB (metrics only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"Total files: {len(df)}\")\n",
    "print(f\"Successful: {(df['status'] == 'success').sum()}\")\n",
    "print(f\"Errors: {(df['status'] == 'error').sum()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detect Issues and Recommend Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect issues\n",
    "df['issues'] = df.apply(detect_audio_issues, axis=1)\n",
    "df['recommended_preprocessing'] = df['issues'].apply(recommend_preprocessing)\n",
    "\n",
    "df_with_issues = df[df['issues'].str.len() > 0]\n",
    "\n",
    "print(f\"Files with issues: {len(df_with_issues)} / {len(df)}\")\n",
    "\n",
    "from collections import Counter\n",
    "all_issues = [issue for issues in df['issues'] for issue in issues]\n",
    "issue_counts = Counter(all_issues)\n",
    "\n",
    "print(\"\\nIssue breakdown:\")\n",
    "for issue, count in issue_counts.most_common():\n",
    "    print(f\"  {issue}: {count} files ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample with issues\n",
    "df_with_issues[['audio_id', 'spectral_rolloff_hz', 'snr_db', 'zcr_mean', \n",
    "                 'loudness_lufs', 'issues', 'recommended_preprocessing']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Metrics Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success = df[df['status'] == 'success']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].hist(df_success['snr_db'], bins=30, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('SNR (dB)')\n",
    "axes[0, 0].set_title('Signal-to-Noise Ratio')\n",
    "axes[0, 0].axvline(x=15, color='r', linestyle='--', label='Threshold')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].hist(df_success['spectral_rolloff_hz'], bins=30, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Spectral Roll-off (Hz)')\n",
    "axes[0, 1].set_title('Bandwidth Indicator')\n",
    "axes[0, 1].axvline(x=1000, color='r', linestyle='--', label='Severe')\n",
    "axes[0, 1].axvline(x=4000, color='orange', linestyle='--', label='Moderate')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[0, 2].hist(df_success['zcr_mean'], bins=30, edgecolor='black')\n",
    "axes[0, 2].set_xlabel('ZCR Mean')\n",
    "axes[0, 2].set_title('Zero Crossing Rate')\n",
    "axes[0, 2].axvline(x=0.05, color='r', linestyle='--', label='Threshold')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "axes[1, 0].hist(df_success['loudness_lufs'], bins=30, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Loudness (LUFS)')\n",
    "axes[1, 0].set_title('Loudness')\n",
    "axes[1, 0].axvline(x=-30, color='r', linestyle='--', label='Low')\n",
    "axes[1, 0].axvline(x=-23, color='g', linestyle='--', label='Target')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].hist(df_success['spectral_flatness'], bins=30, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Spectral Flatness')\n",
    "axes[1, 1].set_title('Tonal vs Noisy')\n",
    "\n",
    "axes[1, 2].hist(df_success['low_freq_energy_ratio'], bins=30, edgecolor='black')\n",
    "axes[1, 2].set_xlabel('Low Freq Energy')\n",
    "axes[1, 2].set_title('Rumble Indicator')\n",
    "axes[1, 2].axvline(x=0.15, color='r', linestyle='--', label='Threshold')\n",
    "axes[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall Statistics:\")\n",
    "print(df_success[['snr_db', 'spectral_rolloff_hz', 'spectral_flatness', \n",
    "                   'zcr_mean', 'loudness_lufs']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPreprocessing Recommendations:\")\n",
    "all_recs = [rec for recs in df['recommended_preprocessing'] for rec in recs]\n",
    "rec_counts = Counter(all_recs)\n",
    "\n",
    "for rec, count in rec_counts.most_common():\n",
    "    print(f\"{rec:30s}: {count:4d} files ({count/len(df)*100:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"../data/audio_quality_analysis.parquet\")\n",
    "df.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"Saved: {output_path}\")\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amia2025-stt-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
