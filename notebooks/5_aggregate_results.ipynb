{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../outputs/aggregated_results\", exist_ok=True)\n",
    "\n",
    "\n",
    "# add inference results to test set\n",
    "def test_set_add_inference_results(df_test_set, df_inference_results):\n",
    "    df_merged = pd.merge(df_test_set, df_inference_results[['blob_path', 'hypothesis', 'processing_time_sec']], left_on='blob_path', right_on='blob_path', how='left')\n",
    "    stt_tag = df_inference_results['model_name'].iloc[0]\n",
    "    df_merged = df_merged.rename(columns={'hypothesis': f'inference_{stt_tag}', 'processing_time_sec': f'processing_time_{stt_tag}'})\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set = pd.read_parquet(\"../data/raw/loc/veterans_history_project_resources_pre2010_test.parquet\")\n",
    "# df_full = pd.read_parquet(\"../data/raw/loc/veterans_history_project_resources_with_audio_features.parquet\")\n",
    "# df_pre2010_test_set = df_full\n",
    "df_pre2010_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example output dfs after inference\n",
    "# results from AWS Transcribe\n",
    "aws_transcribe_results_filepath = \"../outputs/vhp-pre2010-aws-sample500-gpu/inference_results.parquet\"\n",
    "df_aws_transcribe_results = pd.read_parquet(aws_transcribe_results_filepath)\n",
    "df_aws_transcribe_results = df_aws_transcribe_results[df_aws_transcribe_results['error_message'].isnull()]\n",
    "df_aws_transcribe_results = df_aws_transcribe_results[df_aws_transcribe_results['status']==\"success\"]\n",
    "df_aws_transcribe_results = df_aws_transcribe_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "print(df_aws_transcribe_results.info())\n",
    "df_aws_transcribe_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from Chirp2 (GCP)\n",
    "chirp2_results_filepath = \"../outputs/vhp-pre2010-chirp2-sample500-gpu/inference_results.parquet\"\n",
    "df_chirp2_results = pd.read_parquet(chirp2_results_filepath)\n",
    "df_chirp2_results = df_chirp2_results[df_chirp2_results['error_message'].isnull()]\n",
    "df_chirp2_results = df_chirp2_results[df_chirp2_results['status']==\"success\"]\n",
    "df_chirp2_results = df_chirp2_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "print(df_chirp2_results.info())\n",
    "df_chirp2_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from Chirp3 (GCP)\n",
    "chirp3_results_filepath = \"../outputs/vhp-pre2010-chirp3-sample500-gpu/inference_results.parquet\"\n",
    "df_chirp3_results = pd.read_parquet(chirp3_results_filepath)\n",
    "df_chirp3_results = df_chirp3_results[df_chirp3_results['error_message'].isnull()]\n",
    "df_chirp3_results = df_chirp3_results[df_chirp3_results['status']==\"success\"]\n",
    "df_chirp3_results = df_chirp3_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "print(df_chirp3_results.info())\n",
    "df_chirp3_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set, df_aws_transcribe_results)\n",
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_chirp2_results)\n",
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_chirp3_results)\n",
    "df_pre2010_test_set_expanded = df_pre2010_test_set_expanded.dropna(subset=['inference_aws-transcribe', 'inference_gcp-chirp_2', 'inference_gcp-chirp_3'])\n",
    "df_pre2010_test_set_expanded[['transcript_raw_text_only', 'inference_aws-transcribe', 'inference_gcp-chirp_2', 'inference_gcp-chirp_3']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_pre2010_test_set_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set_expanded.to_csv(\"../outputs/aggregated_results/vhp-pre2010-stt-comparison-close-service.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Open models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from NVIDIA Parakeet-TDT-0.6B-v3\n",
    "parakeet_results_filepath = \"../outputs/vhp-pre2010-parakeet-sample1000-runpod-a6000/inference_results.parquet\"\n",
    "df_parakeet_results = pd.read_parquet(parakeet_results_filepath)\n",
    "df_parakeet_results = df_parakeet_results[df_parakeet_results['error_message'].isnull()]\n",
    "df_parakeet_results = df_parakeet_results[df_parakeet_results['status']==\"success\"]\n",
    "df_parakeet_results = df_parakeet_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "print(df_parakeet_results.info())\n",
    "df_parakeet_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from faster-whisper-small (distil - en)\n",
    "faster_whisper_small_results_filepath = \"../outputs/vhp-distil-small-en-sample1000-full-gpu/inference_results.parquet\"\n",
    "df_faster_whisper_small_results = pd.read_parquet(faster_whisper_small_results_filepath)\n",
    "df_faster_whisper_small_results = df_faster_whisper_small_results[df_faster_whisper_small_results['error_message'].isnull()]\n",
    "df_faster_whisper_small_results = df_faster_whisper_small_results[df_faster_whisper_small_results['status']==\"success\"]\n",
    "df_faster_whisper_small_results = df_faster_whisper_small_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "df_faster_whisper_small_results['model_name'] = 'faster-whisper-small'\n",
    "print(df_faster_whisper_small_results.info())\n",
    "df_faster_whisper_small_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from faster-whisper-medium (distil - en)\n",
    "faster_whisper_medium_results_filepath = \"../outputs/vhp-distil-medium-en-sample1000-full-gpu/inference_results.parquet\"\n",
    "df_faster_whisper_medium_results = pd.read_parquet(faster_whisper_medium_results_filepath)\n",
    "df_faster_whisper_medium_results = df_faster_whisper_medium_results[df_faster_whisper_medium_results['error_message'].isnull()]\n",
    "df_faster_whisper_medium_results = df_faster_whisper_medium_results[df_faster_whisper_medium_results['status']==\"success\"]\n",
    "df_faster_whisper_medium_results = df_faster_whisper_medium_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "df_faster_whisper_medium_results['model_name'] = 'faster-whisper-medium'\n",
    "print(df_faster_whisper_medium_results.info())\n",
    "df_faster_whisper_medium_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results from faster-whisper-large-v3 (distil)\n",
    "faster_whisper_large_v3_results_filepath = \"../outputs/vhp-pre2010-distil-large-v3-full-gpu/inference_results.parquet\"\n",
    "df_faster_whisper_large_v3_results = pd.read_parquet(faster_whisper_large_v3_results_filepath)\n",
    "df_faster_whisper_large_v3_results = df_faster_whisper_large_v3_results[df_faster_whisper_large_v3_results['error_message'].isnull()]\n",
    "df_faster_whisper_large_v3_results = df_faster_whisper_large_v3_results[df_faster_whisper_large_v3_results['status']==\"success\"]\n",
    "df_faster_whisper_large_v3_results = df_faster_whisper_large_v3_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "df_faster_whisper_large_v3_results['model_name'] = 'faster-whisper-large-v3'\n",
    "print(df_faster_whisper_large_v3_results.info())\n",
    "df_faster_whisper_large_v3_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from fine-tuned whisper base model (lora)\n",
    "whisper_base_lora_results_filepath = \"../outputs/vhp-pre2010-whisper-v2-base-lora-test-sample200-under-30m-gpu/inference_results.parquet\"\n",
    "df_whisper_base_lora_results = pd.read_parquet(whisper_base_lora_results_filepath)\n",
    "df_whisper_base_lora_results = df_whisper_base_lora_results[df_whisper_base_lora_results['status']==\"success\"]\n",
    "df_whisper_base_lora_results = df_whisper_base_lora_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "df_whisper_base_lora_results['model_name'] = 'whisper-v2-base-lora'\n",
    "print(df_whisper_base_lora_results.info())\n",
    "df_whisper_base_lora_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set, df_parakeet_results)\n",
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set, df_faster_whisper_large_v3_results)\n",
    "# df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_faster_whisper_small_results)\n",
    "# df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_faster_whisper_medium_results)\n",
    "# df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_faster_whisper_large_v3_results)\n",
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_whisper_base_lora_results)\n",
    "# df_pre2010_test_set_expanded = df_pre2010_test_set_expanded.dropna(subset=['inference_parakeet-tdt-0.6b-v3', 'inference_faster-whisper-small', 'inference_faster-whisper-medium', 'inference_faster-whisper-large-v3', 'inference_whisper-v2-base-lora'])\n",
    "df_pre2010_test_set_expanded = df_pre2010_test_set_expanded.dropna(subset=['inference_whisper-v2-base-lora', 'inference_faster-whisper-large-v3'])\n",
    "# df_pre2010_test_set_expanded[['transcript_raw_text_only', 'inference_parakeet-tdt-0.6b-v3', 'inference_faster-whisper-small', 'inference_faster-whisper-medium', 'inference_faster-whisper-large-v3', 'inference_whisper-v2-base-lora']]\n",
    "df_pre2010_test_set_expanded[['transcript_raw_text_only', 'inference_whisper-v2-base-lora', 'inference_faster-whisper-large-v3']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set_expanded.to_csv(\"../outputs/aggregated_results/vhp-pre2010-stt-comparison-open-models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "aggregate evaluation results and inference results (faster-whisper-v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faster_whispser_with_metadata = pd.merge(df_pre2010_test_set, df_faster_whisper_large_v3_results[['file_id', 'blob_path', 'hypothesis', 'model_name', 'processing_time_sec']], left_on='blob_path', right_on='blob_path', how='left')\n",
    "df_faster_whispser_with_metadata  = df_faster_whispser_with_metadata.dropna(subset=['hypothesis'])\n",
    "stt_tag = df_faster_whispser_with_metadata['model_name'].iloc[0]\n",
    "df_faster_whispser_with_metadata = df_faster_whispser_with_metadata.rename(columns={'hypothesis': f'inference_{stt_tag}', 'processing_time_sec': f'processing_time_{stt_tag}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faster_whispser_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faster_whispser_with_metadata.to_csv(f\"../outputs/aggregated_results/vhp-pre2010-distil-large-v3-full-gpu-inference-merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results from whisper large v3 (baseline) v.s. fine-tuned whisper (lora)\n",
    "whisper_large_v3_results_filepath = \"../outputs/vhp-pre2010-whisper-lora-test-sample200-30m-gpu/inference_results.parquet\"\n",
    "\n",
    "df_whisper_large_v3_results = pd.read_parquet(whisper_large_v3_results_filepath)\n",
    "df_whisper_large_v3_results = df_whisper_large_v3_results[df_whisper_large_v3_results['status']==\"success\"]\n",
    "df_whisper_large_v3_results = df_whisper_large_v3_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "df_whisper_large_v3_results['model_name'] = 'whisper-large-v3'\n",
    "print(df_whisper_large_v3_results.info())\n",
    "df_whisper_large_v3_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_lora_results_filepath = \"../outputs/vhp-pre2010-whisper-baseline-test-sample200-30m-gpu/inference_results.parquet\"\n",
    "\n",
    "df_whisper_lora_results = pd.read_parquet(whisper_lora_results_filepath)\n",
    "df_whisper_lora_results = df_whisper_lora_results[df_whisper_lora_results['status']==\"success\"]\n",
    "df_whisper_lora_results = df_whisper_lora_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "df_whisper_lora_results['model_name'] = 'whisper-lora'\n",
    "print(df_whisper_lora_results.info())\n",
    "df_whisper_lora_results.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set, df_whisper_large_v3_results)\n",
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_whisper_lora_results)\n",
    "df_pre2010_test_set_expanded = df_pre2010_test_set_expanded.dropna(subset=['inference_whisper-large-v3', 'inference_whisper-lora'])\n",
    "df_pre2010_test_set_expanded[['transcript_raw_text_only', 'inference_whisper-large-v3', 'inference_whisper-lora']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set_expanded.to_csv(\"../outputs/aggregated_results/vhp-pre2010-stt-comparison-model-finetuning-lora.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results from whisper large v3 (baseline) v.s. fine-tuned whisper (lora)\n",
    "whisper_large_v3_hpf_results_filepath = \"../outputs/vhp-pre2010-whisper-lora-test-sample200-hpf-under-30m-gpu/inference_results.parquet\"\n",
    "\n",
    "df_whisper_large_v3_hpf_results = pd.read_parquet(whisper_large_v3_hpf_results_filepath)\n",
    "df_whisper_large_v3_hpf_results = df_whisper_large_v3_hpf_results[df_whisper_large_v3_hpf_results['status']==\"success\"]\n",
    "df_whisper_large_v3_hpf_results = df_whisper_large_v3_hpf_results.replace('', np.nan).dropna(subset=['hypothesis'])\n",
    "df_whisper_large_v3_hpf_results['model_name'] = 'whisper-large-v3-input-hpf'\n",
    "print(df_whisper_large_v3_hpf_results.info())\n",
    "df_whisper_large_v3_hpf_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set, df_whisper_large_v3_results)\n",
    "df_pre2010_test_set_expanded = test_set_add_inference_results(df_pre2010_test_set_expanded, df_whisper_large_v3_hpf_results)\n",
    "df_pre2010_test_set_expanded = df_pre2010_test_set_expanded.dropna(subset=['inference_whisper-large-v3', 'inference_whisper-large-v3-input-hpf'])\n",
    "df_pre2010_test_set_expanded[['transcript_raw_text_only', 'inference_whisper-large-v3', 'inference_whisper-large-v3-input-hpf']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amia2025-stt-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
