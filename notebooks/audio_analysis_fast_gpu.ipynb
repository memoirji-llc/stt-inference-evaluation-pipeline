{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Quality Analysis - GPU-Accelerated Batch Processing\n",
    "\n",
    "**Optimizations:**\n",
    "- Parallel Azure blob downloads (50-100 files at once)\n",
    "- GPU-accelerated audio processing with torchaudio\n",
    "- Batch spectrogram computation on GPU\n",
    "- Automatic cleanup of downloaded files\n",
    "- Multi-threading for download + GPU processing pipeline\n",
    "\n",
    "**Target:** Process 5000 files in ~1-3 hours (vs 25-30 hours)\n",
    "\n",
    "**Output:** Same as original - `audio_quality_analysis.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pyloudnorm as pyln\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import tempfile\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Azure blob utilities\n",
    "from cloud.azure_utils import list_blobs, download_blob_to_memory\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    # A6000/Ampere optimizations\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"Enabled: TF32 matmul, TF32 cudnn, cudnn benchmark\")\n",
    "\n",
    "# System RAM info\n",
    "total_ram = psutil.virtual_memory().total / 1e9\n",
    "print(f\"System RAM: {total_ram:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='../credentials/creds.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing configuration - OPTIMIZED for parallel CPU + GPU\n",
    "BATCH_SIZE = 32           # GPU batch size\n",
    "DOWNLOAD_WORKERS = 50     # Parallel downloads\n",
    "DOWNLOAD_BATCH_SIZE = 100 # Files in RAM at once\n",
    "TARGET_SR = 16000\n",
    "\n",
    "# Parallel CPU decoding - main bottleneck fix\n",
    "# 8 workers Ã— ~60MB per file = ~500MB extra RAM (safe)\n",
    "DECODE_WORKERS = 8\n",
    "\n",
    "# Memory threshold - trigger GC if above this (in GB)\n",
    "RAM_THRESHOLD_GB = 40\n",
    "\n",
    "# Temp directory for downloaded files (will be cleaned up)\n",
    "TEMP_DIR = Path(tempfile.mkdtemp())\n",
    "print(f\"Temp directory: {TEMP_DIR}\")\n",
    "print(f\"GPU batch size: {BATCH_SIZE} files\")\n",
    "print(f\"Download workers: {DOWNLOAD_WORKERS}\")\n",
    "print(f\"Download batch size: {DOWNLOAD_BATCH_SIZE}\")\n",
    "print(f\"CPU decode workers: {DECODE_WORKERS} (parallel pydub)\")\n",
    "print(f\"RAM threshold: {RAM_THRESHOLD_GB} GB\")\n",
    "\n",
    "\n",
    "def get_ram_usage_gb():\n",
    "    \"\"\"Get current RAM usage in GB.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1e9\n",
    "\n",
    "\n",
    "def force_gc():\n",
    "    \"\"\"Force aggressive garbage collection.\"\"\"\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU-Accelerated Audio Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_to_tensor(audio_bytes, target_sr=16000):\n",
    "    \"\"\"Load audio bytes to torch tensor and resample.\"\"\"\n",
    "    from pydub import AudioSegment\n",
    "    \n",
    "    audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))\n",
    "    audio_segment = audio_segment.set_channels(1)\n",
    "    audio_segment = audio_segment.set_frame_rate(target_sr)\n",
    "    \n",
    "    samples = np.array(audio_segment.get_array_of_samples())\n",
    "    \n",
    "    if audio_segment.sample_width == 2:\n",
    "        waveform = samples.astype(np.float32) / 32768.0\n",
    "    elif audio_segment.sample_width == 4:\n",
    "        waveform = samples.astype(np.float32) / 2147483648.0\n",
    "    else:\n",
    "        waveform = samples.astype(np.float32)\n",
    "    \n",
    "    return torch.from_numpy(waveform).float(), target_sr\n",
    "\n",
    "\n",
    "def _decode_single_audio(args):\n",
    "    \"\"\"Worker function for parallel audio decoding. Returns (audio_id, waveform_numpy, error).\"\"\"\n",
    "    audio_id, audio_bytes, target_sr = args\n",
    "    try:\n",
    "        from pydub import AudioSegment\n",
    "        audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes))\n",
    "        audio_segment = audio_segment.set_channels(1)\n",
    "        audio_segment = audio_segment.set_frame_rate(target_sr)\n",
    "\n",
    "        samples = np.array(audio_segment.get_array_of_samples())\n",
    "\n",
    "        if audio_segment.sample_width == 2:\n",
    "            waveform = samples.astype(np.float32) / 32768.0\n",
    "        elif audio_segment.sample_width == 4:\n",
    "            waveform = samples.astype(np.float32) / 2147483648.0\n",
    "        else:\n",
    "            waveform = samples.astype(np.float32)\n",
    "\n",
    "        return (audio_id, waveform, None)\n",
    "    except Exception as e:\n",
    "        return (audio_id, None, str(e))\n",
    "\n",
    "\n",
    "def decode_audio_parallel(audio_data_list, target_sr=16000, max_workers=8):\n",
    "    \"\"\"Decode multiple audio files in parallel using ProcessPoolExecutor.\"\"\"\n",
    "    args_list = [(audio_id, audio_bytes, target_sr) for audio_id, audio_bytes in audio_data_list]\n",
    "\n",
    "    decoded = []\n",
    "    errors = []\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(_decode_single_audio, args): args[0] for args in args_list}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            audio_id, waveform, error = future.result()\n",
    "            if error:\n",
    "                errors.append({\n",
    "                    'audio_id': audio_id,\n",
    "                    'status': 'error',\n",
    "                    'error_message': f\"Decode error: {error}\"\n",
    "                })\n",
    "            else:\n",
    "                decoded.append((audio_id, torch.from_numpy(waveform).float()))\n",
    "\n",
    "    return decoded, errors\n",
    "\n",
    "\n",
    "def batch_compute_spectrogram(waveforms, sr, n_fft=2048, hop_length=512):\n",
    "    \"\"\"Compute spectrograms for waveforms on GPU - one at a time to avoid OOM on long audio.\"\"\"\n",
    "    freqs = torch.linspace(0, sr/2, n_fft//2 + 1, device=device)\n",
    "\n",
    "    spec_transform = torchaudio.transforms.Spectrogram(\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=n_fft,\n",
    "        window_fn=torch.hann_window,\n",
    "        power=None,\n",
    "        center=True,\n",
    "        pad_mode='reflect',\n",
    "        normalized=False\n",
    "    ).to(device)\n",
    "\n",
    "    results = []\n",
    "    for wv in waveforms:\n",
    "        # Move to GPU\n",
    "        wv_gpu = wv.to(device)\n",
    "\n",
    "        # Ensure minimum length\n",
    "        if len(wv_gpu) < n_fft:\n",
    "            wv_gpu = torch.nn.functional.pad(wv_gpu, (0, n_fft - len(wv_gpu)), mode='constant', value=0)\n",
    "\n",
    "        # Compute spectrogram for single waveform\n",
    "        spec = spec_transform(wv_gpu)\n",
    "        mag = torch.abs(spec)\n",
    "        results.append((mag, freqs))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def snr_cal_batch(waveform, sr):\n",
    "    \"\"\"Calculate SNR using vectorized unfold - no for-loops.\"\"\"\n",
    "    frame_length = 2048\n",
    "    hop_length = 512\n",
    "\n",
    "    if len(waveform) < frame_length:\n",
    "        pad_needed = frame_length - len(waveform)\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, pad_needed), mode='constant', value=0)\n",
    "\n",
    "    pad_length = frame_length // 2\n",
    "    waveform_padded = torch.nn.functional.pad(waveform.unsqueeze(0), (pad_length, pad_length), mode='reflect').squeeze(0)\n",
    "\n",
    "    # Vectorized frame extraction using unfold\n",
    "    frames = waveform_padded.unfold(0, frame_length, hop_length)\n",
    "\n",
    "    if frames.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Vectorized RMS calculation across all frames at once\n",
    "    rms_tensor = torch.sqrt(torch.mean(frames ** 2, dim=1))\n",
    "\n",
    "    noise_frames = int(0.5 * sr / hop_length)\n",
    "\n",
    "    if noise_frames > 0 and noise_frames < len(rms_tensor):\n",
    "        noise_rms = torch.mean(rms_tensor[:noise_frames])\n",
    "        signal_rms = torch.mean(rms_tensor)\n",
    "\n",
    "        if noise_rms > 0:\n",
    "            snr_db = 20 * torch.log10(signal_rms / noise_rms)\n",
    "            return snr_db.item()\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def spectral_rolloff_batch(spec_mag, freqs, sr, roll_percent=0.85):\n",
    "    \"\"\"Calculate spectral rolloff.\"\"\"\n",
    "    cumsum = torch.cumsum(spec_mag, dim=0)\n",
    "    total_energy = cumsum[-1, :]\n",
    "    threshold = roll_percent * total_energy\n",
    "    rolloff_bins = torch.argmax((cumsum >= threshold.unsqueeze(0)).float(), dim=0)\n",
    "    rolloff_hz = freqs[rolloff_bins]\n",
    "    return torch.median(rolloff_hz).item()\n",
    "\n",
    "\n",
    "def spectral_centroid_batch(spec_mag, freqs, sr):\n",
    "    \"\"\"Calculate spectral centroid.\"\"\"\n",
    "    freqs_2d = freqs.unsqueeze(1)\n",
    "    centroid = torch.sum(freqs_2d * spec_mag, dim=0) / (torch.sum(spec_mag, dim=0) + 1e-8)\n",
    "    return torch.median(centroid).item()\n",
    "\n",
    "\n",
    "def spectral_flatness_batch(spec_mag):\n",
    "    \"\"\"Calculate spectral flatness.\"\"\"\n",
    "    spec_safe = spec_mag + 1e-10\n",
    "    log_spec = torch.log(spec_safe)\n",
    "    geometric_mean = torch.exp(torch.mean(log_spec, dim=0))\n",
    "    arithmetic_mean = torch.mean(spec_mag, dim=0)\n",
    "    flatness = geometric_mean / (arithmetic_mean + 1e-10)\n",
    "    return torch.mean(flatness).item()\n",
    "\n",
    "\n",
    "def zcr_batch(waveform):\n",
    "    \"\"\"Calculate zero crossing rate using vectorized unfold - no for-loops.\"\"\"\n",
    "    frame_length = 2048\n",
    "    hop_length = 512\n",
    "\n",
    "    if len(waveform) < frame_length:\n",
    "        pad_needed = frame_length - len(waveform)\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, pad_needed), mode='constant', value=0)\n",
    "\n",
    "    pad_length = frame_length // 2\n",
    "    waveform_padded = torch.nn.functional.pad(waveform, (pad_length, pad_length), mode='constant', value=0)\n",
    "\n",
    "    # Vectorized frame extraction\n",
    "    frames = waveform_padded.unfold(0, frame_length, hop_length)\n",
    "\n",
    "    if frames.shape[0] == 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    # Vectorized sign change calculation per frame\n",
    "    signs = torch.sign(frames)\n",
    "    sign_changes = (torch.abs(torch.diff(signs, dim=1)) > 0).float()\n",
    "    zcr_per_frame = torch.sum(sign_changes, dim=1) / (frame_length - 1)\n",
    "\n",
    "    return torch.mean(zcr_per_frame).item(), torch.var(zcr_per_frame).item()\n",
    "\n",
    "\n",
    "def loudness_cal(waveform, sr):\n",
    "    \"\"\"Calculate loudness (LUFS).\"\"\"\n",
    "    wv_cpu = waveform.cpu().numpy() if torch.is_tensor(waveform) else waveform\n",
    "    min_length = int(0.4 * sr)\n",
    "    if len(wv_cpu) < min_length:\n",
    "        wv_cpu = np.pad(wv_cpu, (0, min_length - len(wv_cpu)), mode='constant', constant_values=0)\n",
    "\n",
    "    meter = pyln.Meter(sr)\n",
    "    loudness = meter.integrated_loudness(wv_cpu)\n",
    "    return float(loudness)\n",
    "\n",
    "\n",
    "def _loudness_worker(args):\n",
    "    \"\"\"Worker function for parallel loudness calculation.\"\"\"\n",
    "    waveform_np, sr = args\n",
    "    try:\n",
    "        min_length = int(0.4 * sr)\n",
    "        if len(waveform_np) < min_length:\n",
    "            waveform_np = np.pad(waveform_np, (0, min_length - len(waveform_np)), mode='constant', constant_values=0)\n",
    "        meter = pyln.Meter(sr)\n",
    "        return meter.integrated_loudness(waveform_np)\n",
    "    except Exception:\n",
    "        return -70.0\n",
    "\n",
    "\n",
    "def loudness_cal_parallel(waveforms, sr, max_workers=8):\n",
    "    \"\"\"Calculate loudness for multiple waveforms in parallel.\"\"\"\n",
    "    waveforms_np = [(wv.cpu().numpy() if torch.is_tensor(wv) else wv, sr) for wv in waveforms]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(_loudness_worker, waveforms_np))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def low_frequency_energy_batch(spec_mag, freqs, sr, cutoff_hz=80):\n",
    "    \"\"\"Calculate low frequency energy ratio.\"\"\"\n",
    "    low_freq_mask = freqs < cutoff_hz\n",
    "    low_energy = torch.sum(spec_mag[low_freq_mask, :])\n",
    "    total_energy = torch.sum(spec_mag)\n",
    "\n",
    "    if total_energy > 0:\n",
    "        return (low_energy / total_energy).item()\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_batch_gpu(audio_data_list):\n",
    "    \"\"\"Analyze a batch of audio files on GPU with parallel CPU decoding.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # PARALLEL DECODE: This was the main bottleneck - pydub is CPU-bound\n",
    "    # Using ProcessPoolExecutor decodes 8 files simultaneously\n",
    "    decoded_waveforms, decode_errors = decode_audio_parallel(\n",
    "        audio_data_list,\n",
    "        target_sr=TARGET_SR,\n",
    "        max_workers=DECODE_WORKERS\n",
    "    )\n",
    "    results.extend(decode_errors)\n",
    "\n",
    "    if not decoded_waveforms:\n",
    "        return results\n",
    "\n",
    "    audio_ids = [aid for aid, _ in decoded_waveforms]\n",
    "    waveforms = [wv for _, wv in decoded_waveforms]\n",
    "\n",
    "    # BATCHED SPECTROGRAM: Process all waveforms on GPU in single batch\n",
    "    spec_results = batch_compute_spectrogram(waveforms, TARGET_SR)\n",
    "\n",
    "    # PARALLEL LOUDNESS: CPU-bound pyloudnorm in parallel\n",
    "    loudness_values = loudness_cal_parallel(waveforms, TARGET_SR, max_workers=DECODE_WORKERS)\n",
    "\n",
    "    # Process remaining metrics (already vectorized SNR/ZCR)\n",
    "    for i, (audio_id, wv) in enumerate(zip(audio_ids, waveforms)):\n",
    "        try:\n",
    "            spec_mag, freqs = spec_results[i]\n",
    "            wv_gpu = wv.to(device)\n",
    "\n",
    "            duration_sec = len(wv) / TARGET_SR\n",
    "            snr = snr_cal_batch(wv_gpu, TARGET_SR)\n",
    "            rolloff = spectral_rolloff_batch(spec_mag, freqs, TARGET_SR)\n",
    "            centroid = spectral_centroid_batch(spec_mag, freqs, TARGET_SR)\n",
    "            flatness = spectral_flatness_batch(spec_mag)\n",
    "            zcr_mean, zcr_var = zcr_batch(wv_gpu)\n",
    "            low_freq_ratio = low_frequency_energy_batch(spec_mag, freqs, TARGET_SR)\n",
    "            loudness = loudness_values[i]\n",
    "\n",
    "            results.append({\n",
    "                'audio_id': audio_id,\n",
    "                'sample_rate': TARGET_SR,\n",
    "                'duration_sec': float(duration_sec),\n",
    "                'snr_db': float(snr),\n",
    "                'spectral_rolloff_hz': float(rolloff),\n",
    "                'spectral_flatness': float(flatness),\n",
    "                'spectral_centroid_hz': float(centroid),\n",
    "                'zcr_mean': float(zcr_mean),\n",
    "                'zcr_var': float(zcr_var),\n",
    "                'loudness_lufs': float(loudness),\n",
    "                'low_freq_energy_ratio': float(low_freq_ratio),\n",
    "                'status': 'success'\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'audio_id': audio_id,\n",
    "                'status': 'error',\n",
    "                'error_message': f\"Processing error: {str(e)}\"\n",
    "            })\n",
    "\n",
    "    del waveforms, spec_results, decoded_waveforms\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Download Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_single_blob(blob_path):\n",
    "    \"\"\"\n",
    "    Download a single blob and return (audio_id, audio_bytes).\n",
    "    \"\"\"\n",
    "    audio_id = Path(blob_path).parent.name  # Extract ID from path\n",
    "    try:\n",
    "        audio_bytes = download_blob_to_memory(blob_path)\n",
    "        return (audio_id, audio_bytes, None)\n",
    "    except Exception as e:\n",
    "        return (audio_id, None, str(e))\n",
    "\n",
    "\n",
    "def download_batch_parallel(blob_paths, max_workers=100):\n",
    "    \"\"\"\n",
    "    Download multiple blobs in parallel.\n",
    "    \n",
    "    Args:\n",
    "        blob_paths: List of blob paths to download\n",
    "        max_workers: Number of parallel downloads\n",
    "    \n",
    "    Returns:\n",
    "        List of (audio_id, audio_bytes) tuples (only successful downloads)\n",
    "        List of error dictionaries\n",
    "    \"\"\"\n",
    "    audio_data = []\n",
    "    errors = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(download_single_blob, path): path for path in blob_paths}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading\"):\n",
    "            audio_id, audio_bytes, error = future.result()\n",
    "            \n",
    "            if error:\n",
    "                errors.append({\n",
    "                    'audio_id': audio_id,\n",
    "                    'status': 'error',\n",
    "                    'error_message': f\"Download error: {error}\"\n",
    "                })\n",
    "            else:\n",
    "                audio_data.append((audio_id, audio_bytes))\n",
    "    \n",
    "    return audio_data, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all audio/video blobs from Azure\n",
    "blob_prefix = \"loc_vhp/\"\n",
    "\n",
    "print(f\"Listing blobs with prefix: {blob_prefix}\")\n",
    "audio_blobs = list_blobs(blob_prefix)\n",
    "\n",
    "# Filter for ORIGINAL VHP source files only (not NFA-segmented WAV files)\n",
    "# VHP project naming convention: audio.mp3 or video.mp4\n",
    "audio_blobs = [b for b in audio_blobs if b.endswith('/audio.mp3') or b.endswith('/video.mp4')]\n",
    "\n",
    "print(f\"Found {len(audio_blobs)} original VHP media files\")\n",
    "print(f\"\\nFirst 5 files:\")\n",
    "for blob in audio_blobs[:5]:\n",
    "    print(f\"  - {blob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING: Uncomment to limit processing for testing\n",
    "SAMPLE_SIZE = 10\n",
    "audio_blobs = audio_blobs[:SAMPLE_SIZE]\n",
    "print(f\"\\nðŸ§ª TEST MODE: Processing only first {SAMPLE_SIZE} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All Files (Download + GPU Processing Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "all_results = []\n",
    "total_files = len(audio_blobs)\n",
    "\n",
    "print(f\"\\nProcessing {total_files} files...\")\n",
    "print(f\"Download batch size: {DOWNLOAD_BATCH_SIZE}\")\n",
    "print(f\"GPU batch size: {BATCH_SIZE}\")\n",
    "print(f\"CPU decode workers: {DECODE_WORKERS} (parallel pydub)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Process in large download batches\n",
    "for i in range(0, total_files, DOWNLOAD_BATCH_SIZE):\n",
    "    batch_blobs = audio_blobs[i:i + DOWNLOAD_BATCH_SIZE]\n",
    "    \n",
    "    print(f\"\\n[Batch {i//DOWNLOAD_BATCH_SIZE + 1}] Downloading {len(batch_blobs)} files...\")\n",
    "    \n",
    "    # Download batch in parallel\n",
    "    audio_data, download_errors = download_batch_parallel(batch_blobs, max_workers=DOWNLOAD_WORKERS)\n",
    "    all_results.extend(download_errors)\n",
    "    \n",
    "    print(f\"Downloaded: {len(audio_data)} files, Errors: {len(download_errors)}\")\n",
    "    \n",
    "    # Check RAM before processing\n",
    "    ram_before = get_ram_usage_gb()\n",
    "    print(f\"RAM usage: {ram_before:.1f} GB\")\n",
    "    \n",
    "    # Process downloaded files in GPU batches\n",
    "    print(f\"Processing (parallel decode + GPU metrics)...\")\n",
    "    for j in range(0, len(audio_data), BATCH_SIZE):\n",
    "        gpu_batch = audio_data[j:j + BATCH_SIZE]\n",
    "        batch_num = j // BATCH_SIZE + 1\n",
    "        total_batches = (len(audio_data) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "        print(f\"  GPU batch {batch_num}/{total_batches} ({len(gpu_batch)} files)...\", end=\" \", flush=True)\n",
    "        \n",
    "        batch_start = time.time()\n",
    "        batch_results = analyze_audio_batch_gpu(gpu_batch)\n",
    "        batch_time = time.time() - batch_start\n",
    "        \n",
    "        all_results.extend(batch_results)\n",
    "        success = sum(1 for r in batch_results if r.get('status') == 'success')\n",
    "        print(f\"done in {batch_time:.1f}s ({success} ok)\")\n",
    "        \n",
    "        # Clear processed batch from memory immediately\n",
    "        for k in range(len(gpu_batch)):\n",
    "            audio_data[j + k] = None  # Release reference\n",
    "    \n",
    "    # Aggressive cleanup after each download batch\n",
    "    del audio_data\n",
    "    force_gc()\n",
    "    \n",
    "    # Check RAM after processing\n",
    "    ram_after = get_ram_usage_gb()\n",
    "    print(f\"RAM after GC: {ram_after:.1f} GB\")\n",
    "    \n",
    "    # Extra GC if above threshold\n",
    "    if ram_after > RAM_THRESHOLD_GB:\n",
    "        print(f\"âš ï¸  RAM above {RAM_THRESHOLD_GB}GB, forcing extra GC...\")\n",
    "        force_gc()\n",
    "        time.sleep(1)\n",
    "        force_gc()\n",
    "        print(f\"RAM after extra GC: {get_ram_usage_gb():.1f} GB\")\n",
    "    \n",
    "    # Progress update\n",
    "    elapsed = time.time() - start_time\n",
    "    processed = min(i + DOWNLOAD_BATCH_SIZE, total_files)\n",
    "    rate = processed / elapsed\n",
    "    remaining = (total_files - processed) / rate if rate > 0 else 0\n",
    "    \n",
    "    print(f\"Progress: {processed}/{total_files} ({processed/total_files*100:.1f}%)\")\n",
    "    print(f\"Elapsed: {elapsed/60:.1f} min, Rate: {rate:.1f} files/sec, ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ“ COMPLETED\")\n",
    "print(f\"Total files: {len(all_results)}\")\n",
    "print(f\"Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"Average rate: {len(all_results)/total_time:.2f} files/second\")\n",
    "print(f\"Success: {sum(1 for r in all_results if r.get('status') == 'success')}\")\n",
    "print(f\"Errors: {sum(1 for r in all_results if r.get('status') == 'error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue Detection and Preprocessing Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_audio_issues(row):\n",
    "    \"\"\"Detect audio issues based on quality metrics.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    if row['status'] != 'success':\n",
    "        return issues\n",
    "    \n",
    "    # 1. Bandwidth-limited\n",
    "    if row['spectral_rolloff_hz'] < 1000:\n",
    "        issues.append('bandwidth_limited_severe')\n",
    "    elif row['spectral_rolloff_hz'] < 4000:\n",
    "        issues.append('bandwidth_limited_moderate')\n",
    "    \n",
    "    # 2. High noise\n",
    "    if row['zcr_mean'] > 0.05:\n",
    "        issues.append('high_noise_zcr')\n",
    "    if row['snr_db'] < 15:\n",
    "        issues.append('high_noise_snr')\n",
    "    \n",
    "    # 3. Low-frequency rumble\n",
    "    if row['low_freq_energy_ratio'] > 0.15:\n",
    "        issues.append('low_frequency_rumble')\n",
    "    \n",
    "    # 4. Low loudness\n",
    "    if row['loudness_lufs'] < -30:\n",
    "        issues.append('low_loudness')\n",
    "    \n",
    "    # 5. Very flat spectrum\n",
    "    if row['spectral_flatness'] > 0.8:\n",
    "        issues.append('very_flat_spectrum')\n",
    "    \n",
    "    return issues\n",
    "\n",
    "\n",
    "def recommend_preprocessing(issues):\n",
    "    \"\"\"Recommend preprocessing methods based on detected issues.\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # Always normalize loudness\n",
    "    recommendations.append('loudness_normalization')\n",
    "    \n",
    "    # Bandwidth-limited â†’ EQ boost\n",
    "    if 'bandwidth_limited_severe' in issues or 'bandwidth_limited_moderate' in issues:\n",
    "        recommendations.append('eq_high_freq_boost')\n",
    "    \n",
    "    # High noise â†’ Noise reduction\n",
    "    if 'high_noise_zcr' in issues or 'high_noise_snr' in issues:\n",
    "        recommendations.append('noise_reduction')\n",
    "    \n",
    "    # Low-frequency rumble â†’ High-pass filter\n",
    "    if 'low_frequency_rumble' in issues:\n",
    "        recommendations.append('highpass_filter')\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Detect issues\n",
    "df['issues'] = df.apply(detect_audio_issues, axis=1)\n",
    "df['recommended_preprocessing'] = df['issues'].apply(recommend_preprocessing)\n",
    "\n",
    "print(f\"\\nFiles with issues: {(df['issues'].str.len() > 0).sum()} / {len(df)}\")\n",
    "\n",
    "from collections import Counter\n",
    "all_issues = [issue for issues in df['issues'] for issue in issues]\n",
    "issue_counts = Counter(all_issues)\n",
    "\n",
    "print(\"\\nIssue breakdown:\")\n",
    "for issue, count in issue_counts.most_common():\n",
    "    print(f\"  {issue}: {count} files ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success = df[df['status'] == 'success']\n",
    "\n",
    "print(\"Overall Statistics:\")\n",
    "print(df_success[['snr_db', 'spectral_rolloff_hz', 'spectral_flatness', \n",
    "                   'zcr_mean', 'loudness_lufs']].describe())\n",
    "\n",
    "print(\"\\nPreprocessing Recommendations:\")\n",
    "all_recs = [rec for recs in df['recommended_preprocessing'] for rec in recs]\n",
    "rec_counts = Counter(all_recs)\n",
    "\n",
    "for rec, count in rec_counts.most_common():\n",
    "    print(f\"{rec:30s}: {count:4d} files ({count/len(df)*100:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"../data/audio_quality_analysis.parquet\")\n",
    "df.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"âœ“ Saved: {output_path}\")\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFile size: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temp directory\n",
    "import shutil\n",
    "\n",
    "if TEMP_DIR.exists():\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "    print(f\"âœ“ Cleaned up temp directory: {TEMP_DIR}\")\n",
    "\n",
    "# Clear GPU memory\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"âœ“ Cleared GPU memory\")\n",
    "\n",
    "print(\"\\nâœ“ All done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amia2025-stt-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
