{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Quality Analysis - GPU-Accelerated Batch Processing\n",
    "\n",
    "**Optimizations:**\n",
    "- Parallel Azure blob downloads (50-100 files at once)\n",
    "- GPU-accelerated audio processing with torchaudio\n",
    "- Batch spectrogram computation on GPU\n",
    "- Automatic cleanup of downloaded files\n",
    "- Multi-threading for download + GPU processing pipeline\n",
    "\n",
    "**Target:** Process 5000 files in ~1-3 hours (vs 25-30 hours)\n",
    "\n",
    "**Output:** Same as original - `audio_quality_analysis.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pyloudnorm as pyln\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import tempfile\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Azure blob utilities\n",
    "from azure_utils import list_blobs, download_blob_to_memory\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Azure authentication environment variables\n",
    "os.environ['AZURE_STORAGE_ACCOUNT'] = 'stgamiadata26828'\n",
    "os.environ['AZURE_STORAGE_CONTAINER'] = 'audio-raw'\n",
    "os.environ['AZURE_AUTH'] = 'connection_string'\n",
    "os.environ['AZURE_STORAGE_CONNECTION_STRING'] = 'DefaultEndpointsProtocol=https;AccountName=stgamiadata26828;AccountKey=Ol7WsOhceB+UxH5x33nfL6dZZLG4coJBgaWAqsbuzMMZLZKnjCS8BCbeinEIdN/h8437NQosRiAI+AStBeJqdw==;EndpointSuffix=core.windows.net'\n",
    "\n",
    "print(\"âœ“ Azure credentials set in environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing configuration\n",
    "BATCH_SIZE = 64  # Number of files to process on GPU simultaneously\n",
    "DOWNLOAD_WORKERS = 100  # Parallel downloads\n",
    "DOWNLOAD_BATCH_SIZE = 200  # Files to download before processing\n",
    "TARGET_SR = 16000  # Target sample rate\n",
    "\n",
    "# Temp directory for downloaded files (will be cleaned up)\n",
    "TEMP_DIR = Path(tempfile.mkdtemp())\n",
    "print(f\"Temp directory: {TEMP_DIR}\")\n",
    "print(f\"Batch size: {BATCH_SIZE} files\")\n",
    "print(f\"Download workers: {DOWNLOAD_WORKERS}\")\n",
    "print(f\"Download batch size: {DOWNLOAD_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU-Accelerated Audio Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_to_tensor(audio_bytes, target_sr=16000):\n",
    "    \"\"\"\n",
    "    Load audio bytes to torch tensor and resample.\n",
    "    Handles MP3, MP4, WAV, etc.\n",
    "    \"\"\"\n",
    "    # Save to temp file (torchaudio needs file path)\n",
    "    with tempfile.NamedTemporaryFile(suffix='.tmp', delete=False) as tmp:\n",
    "        tmp.write(audio_bytes)\n",
    "        tmp_path = tmp.name\n",
    "    \n",
    "    try:\n",
    "        # Load audio\n",
    "        waveform, sr = torchaudio.load(tmp_path)\n",
    "        \n",
    "        # Convert to mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != target_sr:\n",
    "            resampler = torchaudio.transforms.Resample(sr, target_sr)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        return waveform.squeeze(), target_sr\n",
    "    \n",
    "    finally:\n",
    "        # Clean up temp file\n",
    "        os.unlink(tmp_path)\n",
    "\n",
    "\n",
    "def batch_compute_spectrogram(waveforms, sr, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Compute spectrograms for batch of waveforms on GPU.\n",
    "    \n",
    "    Args:\n",
    "        waveforms: List of 1D tensors (different lengths OK)\n",
    "        sr: Sample rate\n",
    "    \n",
    "    Returns:\n",
    "        List of spectrograms (mag + phase) on GPU\n",
    "    \"\"\"\n",
    "    spectrograms = []\n",
    "    \n",
    "    for wv in waveforms:\n",
    "        # Move to GPU\n",
    "        wv_gpu = wv.to(device)\n",
    "        \n",
    "        # Compute spectrogram\n",
    "        spec_transform = torchaudio.transforms.Spectrogram(\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            power=None  # Returns complex\n",
    "        ).to(device)\n",
    "        \n",
    "        spec = spec_transform(wv_gpu)\n",
    "        mag = torch.abs(spec)\n",
    "        spectrograms.append(mag)\n",
    "    \n",
    "    return spectrograms\n",
    "\n",
    "\n",
    "def snr_cal_batch(waveform, sr):\n",
    "    \"\"\"Calculate SNR for single waveform (tensor)\"\"\"\n",
    "    # RMS calculation\n",
    "    frame_length = 2048\n",
    "    hop_length = 512\n",
    "    \n",
    "    # Compute RMS per frame\n",
    "    rms = torch.sqrt(torch.nn.functional.unfold(\n",
    "        waveform.unsqueeze(0).unsqueeze(0).unsqueeze(0),\n",
    "        kernel_size=(1, frame_length),\n",
    "        stride=(1, hop_length)\n",
    "    ).pow(2).mean(dim=1)).squeeze()\n",
    "    \n",
    "    # Assume first 0.5 seconds is noise\n",
    "    noise_frames = int(0.5 * sr / hop_length)\n",
    "    noise_rms = torch.mean(rms[:noise_frames])\n",
    "    signal_rms = torch.mean(rms)\n",
    "    \n",
    "    snr_db = 20 * torch.log10(signal_rms / (noise_rms + 1e-8))\n",
    "    return snr_db.item()\n",
    "\n",
    "\n",
    "def spectral_rolloff_batch(spec, sr, roll_percent=0.85):\n",
    "    \"\"\"\n",
    "    Calculate spectral rolloff from spectrogram (GPU tensor).\n",
    "    \"\"\"\n",
    "    # Cumulative sum along frequency axis\n",
    "    cumsum = torch.cumsum(spec, dim=0)\n",
    "    total_energy = cumsum[-1, :]\n",
    "    \n",
    "    # Find frequency where cumsum reaches roll_percent of total\n",
    "    threshold = roll_percent * total_energy\n",
    "    rolloff_bins = torch.argmax((cumsum >= threshold).float(), dim=0)\n",
    "    \n",
    "    # Convert bins to Hz\n",
    "    freqs = torch.linspace(0, sr/2, spec.shape[0], device=device)\n",
    "    rolloff_hz = freqs[rolloff_bins]\n",
    "    \n",
    "    return torch.median(rolloff_hz).item()\n",
    "\n",
    "\n",
    "def spectral_centroid_batch(spec, sr):\n",
    "    \"\"\"\n",
    "    Calculate spectral centroid from spectrogram (GPU tensor).\n",
    "    \"\"\"\n",
    "    freqs = torch.linspace(0, sr/2, spec.shape[0], device=device).unsqueeze(1)\n",
    "    \n",
    "    # Weighted average frequency\n",
    "    centroid = torch.sum(freqs * spec, dim=0) / (torch.sum(spec, dim=0) + 1e-8)\n",
    "    \n",
    "    return torch.median(centroid).item()\n",
    "\n",
    "\n",
    "def spectral_flatness_batch(spec):\n",
    "    \"\"\"\n",
    "    Calculate spectral flatness from spectrogram (GPU tensor).\n",
    "    \"\"\"\n",
    "    # Geometric mean / arithmetic mean\n",
    "    geometric_mean = torch.exp(torch.mean(torch.log(spec + 1e-8), dim=0))\n",
    "    arithmetic_mean = torch.mean(spec, dim=0)\n",
    "    \n",
    "    flatness = geometric_mean / (arithmetic_mean + 1e-8)\n",
    "    \n",
    "    return torch.mean(flatness).item()\n",
    "\n",
    "\n",
    "def zcr_batch(waveform):\n",
    "    \"\"\"\n",
    "    Calculate zero crossing rate from waveform (GPU tensor).\n",
    "    \"\"\"\n",
    "    # Sign changes\n",
    "    signs = torch.sign(waveform)\n",
    "    sign_changes = torch.abs(torch.diff(signs))\n",
    "    \n",
    "    # ZCR per frame\n",
    "    frame_length = 2048\n",
    "    hop_length = 512\n",
    "    \n",
    "    # Unfold into frames\n",
    "    frames = sign_changes.unfold(0, frame_length, hop_length)\n",
    "    zcr = torch.sum(frames > 0, dim=1).float() / frame_length\n",
    "    \n",
    "    return torch.mean(zcr).item(), torch.var(zcr).item()\n",
    "\n",
    "\n",
    "def loudness_cal(waveform, sr):\n",
    "    \"\"\"\n",
    "    Calculate loudness (LUFS) - requires CPU.\n",
    "    \"\"\"\n",
    "    wv_cpu = waveform.cpu().numpy()\n",
    "    meter = pyln.Meter(sr)\n",
    "    loudness = meter.integrated_loudness(wv_cpu)\n",
    "    return float(loudness)\n",
    "\n",
    "\n",
    "def low_frequency_energy_batch(spec, sr, cutoff_hz=80):\n",
    "    \"\"\"\n",
    "    Calculate low frequency energy ratio from spectrogram (GPU tensor).\n",
    "    \"\"\"\n",
    "    freqs = torch.linspace(0, sr/2, spec.shape[0], device=device)\n",
    "    low_freq_mask = freqs < cutoff_hz\n",
    "    \n",
    "    low_energy = torch.sum(spec[low_freq_mask, :])\n",
    "    total_energy = torch.sum(spec)\n",
    "    \n",
    "    ratio = low_energy / (total_energy + 1e-8)\n",
    "    return ratio.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_batch_gpu(audio_data_list):\n",
    "    \"\"\"\n",
    "    Analyze a batch of audio files on GPU.\n",
    "    \n",
    "    Args:\n",
    "        audio_data_list: List of (audio_id, audio_bytes) tuples\n",
    "    \n",
    "    Returns:\n",
    "        List of result dictionaries\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    waveforms = []\n",
    "    audio_ids = []\n",
    "    \n",
    "    # Load all audio files\n",
    "    for audio_id, audio_bytes in audio_data_list:\n",
    "        try:\n",
    "            wv, sr = load_audio_to_tensor(audio_bytes, target_sr=TARGET_SR)\n",
    "            waveforms.append(wv)\n",
    "            audio_ids.append(audio_id)\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'audio_id': audio_id,\n",
    "                'status': 'error',\n",
    "                'error_message': f\"Load error: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    if not waveforms:\n",
    "        return results\n",
    "    \n",
    "    # Compute spectrograms on GPU (batch)\n",
    "    spectrograms = batch_compute_spectrogram(waveforms, TARGET_SR)\n",
    "    \n",
    "    # Process each file\n",
    "    for i, (audio_id, wv, spec) in enumerate(zip(audio_ids, waveforms, spectrograms)):\n",
    "        try:\n",
    "            # Move waveform to GPU for processing\n",
    "            wv_gpu = wv.to(device)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            duration_sec = len(wv) / TARGET_SR\n",
    "            \n",
    "            # GPU-based metrics\n",
    "            snr = snr_cal_batch(wv_gpu, TARGET_SR)\n",
    "            rolloff = spectral_rolloff_batch(spec, TARGET_SR)\n",
    "            centroid = spectral_centroid_batch(spec, TARGET_SR)\n",
    "            flatness = spectral_flatness_batch(spec)\n",
    "            zcr_mean, zcr_var = zcr_batch(wv_gpu)\n",
    "            low_freq_ratio = low_frequency_energy_batch(spec, TARGET_SR)\n",
    "            \n",
    "            # CPU-based metric (loudness)\n",
    "            loudness = loudness_cal(wv, TARGET_SR)\n",
    "            \n",
    "            results.append({\n",
    "                'audio_id': audio_id,\n",
    "                'sample_rate': TARGET_SR,\n",
    "                'duration_sec': float(duration_sec),\n",
    "                'snr_db': float(snr),\n",
    "                'spectral_rolloff_hz': float(rolloff),\n",
    "                'spectral_flatness': float(flatness),\n",
    "                'spectral_centroid_hz': float(centroid),\n",
    "                'zcr_mean': float(zcr_mean),\n",
    "                'zcr_var': float(zcr_var),\n",
    "                'loudness_lufs': float(loudness),\n",
    "                'low_freq_energy_ratio': float(low_freq_ratio),\n",
    "                'status': 'success'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'audio_id': audio_id,\n",
    "                'status': 'error',\n",
    "                'error_message': f\"Processing error: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    del waveforms, spectrograms\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Download Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_single_blob(blob_path):\n",
    "    \"\"\"\n",
    "    Download a single blob and return (audio_id, audio_bytes).\n",
    "    \"\"\"\n",
    "    audio_id = Path(blob_path).parent.name  # Extract ID from path\n",
    "    try:\n",
    "        audio_bytes = download_blob_to_memory(blob_path)\n",
    "        return (audio_id, audio_bytes, None)\n",
    "    except Exception as e:\n",
    "        return (audio_id, None, str(e))\n",
    "\n",
    "\n",
    "def download_batch_parallel(blob_paths, max_workers=100):\n",
    "    \"\"\"\n",
    "    Download multiple blobs in parallel.\n",
    "    \n",
    "    Args:\n",
    "        blob_paths: List of blob paths to download\n",
    "        max_workers: Number of parallel downloads\n",
    "    \n",
    "    Returns:\n",
    "        List of (audio_id, audio_bytes) tuples (only successful downloads)\n",
    "        List of error dictionaries\n",
    "    \"\"\"\n",
    "    audio_data = []\n",
    "    errors = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(download_single_blob, path): path for path in blob_paths}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading\"):\n",
    "            audio_id, audio_bytes, error = future.result()\n",
    "            \n",
    "            if error:\n",
    "                errors.append({\n",
    "                    'audio_id': audio_id,\n",
    "                    'status': 'error',\n",
    "                    'error_message': f\"Download error: {error}\"\n",
    "                })\n",
    "            else:\n",
    "                audio_data.append((audio_id, audio_bytes))\n",
    "    \n",
    "    return audio_data, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all audio/video blobs from Azure\n",
    "blob_prefix = \"loc_vhp/\"\n",
    "\n",
    "print(f\"Listing blobs with prefix: {blob_prefix}\")\n",
    "audio_blobs = list_blobs(blob_prefix)\n",
    "\n",
    "# Filter for audio AND video files\n",
    "media_extensions = ('.mp3', '.mp4', '.wav', '.m4a', '.flac', '.ogg')\n",
    "audio_blobs = [b for b in audio_blobs if b.lower().endswith(media_extensions)]\n",
    "\n",
    "print(f\"Found {len(audio_blobs)} media files\")\n",
    "print(f\"\\nFirst 5 files:\")\n",
    "for blob in audio_blobs[:5]:\n",
    "    print(f\"  - {blob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING: Uncomment to limit processing for testing\n",
    "# SAMPLE_SIZE = 100\n",
    "# audio_blobs = audio_blobs[:SAMPLE_SIZE]\n",
    "# print(f\"\\nðŸ§ª TEST MODE: Processing only first {SAMPLE_SIZE} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All Files (Download + GPU Processing Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "all_results = []\n",
    "total_files = len(audio_blobs)\n",
    "\n",
    "print(f\"\\nProcessing {total_files} files...\")\n",
    "print(f\"Download batch size: {DOWNLOAD_BATCH_SIZE}\")\n",
    "print(f\"GPU batch size: {BATCH_SIZE}\")\n",
    "print(f\"Download workers: {DOWNLOAD_WORKERS}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Process in large download batches\n",
    "for i in range(0, total_files, DOWNLOAD_BATCH_SIZE):\n",
    "    batch_blobs = audio_blobs[i:i + DOWNLOAD_BATCH_SIZE]\n",
    "    \n",
    "    print(f\"\\n[Batch {i//DOWNLOAD_BATCH_SIZE + 1}] Downloading {len(batch_blobs)} files...\")\n",
    "    \n",
    "    # Download batch in parallel\n",
    "    audio_data, download_errors = download_batch_parallel(batch_blobs, max_workers=DOWNLOAD_WORKERS)\n",
    "    all_results.extend(download_errors)\n",
    "    \n",
    "    print(f\"Downloaded: {len(audio_data)} files, Errors: {len(download_errors)}\")\n",
    "    \n",
    "    # Process downloaded files in GPU batches\n",
    "    print(f\"Processing on GPU...\")\n",
    "    for j in range(0, len(audio_data), BATCH_SIZE):\n",
    "        gpu_batch = audio_data[j:j + BATCH_SIZE]\n",
    "        batch_results = analyze_audio_batch_gpu(gpu_batch)\n",
    "        all_results.extend(batch_results)\n",
    "    \n",
    "    # Clear memory after batch\n",
    "    del audio_data\n",
    "    gc.collect()\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Progress update\n",
    "    elapsed = time.time() - start_time\n",
    "    processed = min(i + DOWNLOAD_BATCH_SIZE, total_files)\n",
    "    rate = processed / elapsed\n",
    "    remaining = (total_files - processed) / rate if rate > 0 else 0\n",
    "    \n",
    "    print(f\"Progress: {processed}/{total_files} ({processed/total_files*100:.1f}%)\")\n",
    "    print(f\"Elapsed: {elapsed/60:.1f} min, Rate: {rate:.1f} files/sec, ETA: {remaining/60:.1f} min\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ“ COMPLETED\")\n",
    "print(f\"Total files: {len(all_results)}\")\n",
    "print(f\"Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"Average rate: {len(all_results)/total_time:.2f} files/second\")\n",
    "print(f\"Success: {sum(1 for r in all_results if r.get('status') == 'success')}\")\n",
    "print(f\"Errors: {sum(1 for r in all_results if r.get('status') == 'error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue Detection and Preprocessing Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_audio_issues(row):\n",
    "    \"\"\"Detect audio issues based on quality metrics.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    if row['status'] != 'success':\n",
    "        return issues\n",
    "    \n",
    "    # 1. Bandwidth-limited\n",
    "    if row['spectral_rolloff_hz'] < 1000:\n",
    "        issues.append('bandwidth_limited_severe')\n",
    "    elif row['spectral_rolloff_hz'] < 4000:\n",
    "        issues.append('bandwidth_limited_moderate')\n",
    "    \n",
    "    # 2. High noise\n",
    "    if row['zcr_mean'] > 0.05:\n",
    "        issues.append('high_noise_zcr')\n",
    "    if row['snr_db'] < 15:\n",
    "        issues.append('high_noise_snr')\n",
    "    \n",
    "    # 3. Low-frequency rumble\n",
    "    if row['low_freq_energy_ratio'] > 0.15:\n",
    "        issues.append('low_frequency_rumble')\n",
    "    \n",
    "    # 4. Low loudness\n",
    "    if row['loudness_lufs'] < -30:\n",
    "        issues.append('low_loudness')\n",
    "    \n",
    "    # 5. Very flat spectrum\n",
    "    if row['spectral_flatness'] > 0.8:\n",
    "        issues.append('very_flat_spectrum')\n",
    "    \n",
    "    return issues\n",
    "\n",
    "\n",
    "def recommend_preprocessing(issues):\n",
    "    \"\"\"Recommend preprocessing methods based on detected issues.\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # Always normalize loudness\n",
    "    recommendations.append('loudness_normalization')\n",
    "    \n",
    "    # Bandwidth-limited â†’ EQ boost\n",
    "    if 'bandwidth_limited_severe' in issues or 'bandwidth_limited_moderate' in issues:\n",
    "        recommendations.append('eq_high_freq_boost')\n",
    "    \n",
    "    # High noise â†’ Noise reduction\n",
    "    if 'high_noise_zcr' in issues or 'high_noise_snr' in issues:\n",
    "        recommendations.append('noise_reduction')\n",
    "    \n",
    "    # Low-frequency rumble â†’ High-pass filter\n",
    "    if 'low_frequency_rumble' in issues:\n",
    "        recommendations.append('highpass_filter')\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Detect issues\n",
    "df['issues'] = df.apply(detect_audio_issues, axis=1)\n",
    "df['recommended_preprocessing'] = df['issues'].apply(recommend_preprocessing)\n",
    "\n",
    "print(f\"\\nFiles with issues: {(df['issues'].str.len() > 0).sum()} / {len(df)}\")\n",
    "\n",
    "from collections import Counter\n",
    "all_issues = [issue for issues in df['issues'] for issue in issues]\n",
    "issue_counts = Counter(all_issues)\n",
    "\n",
    "print(\"\\nIssue breakdown:\")\n",
    "for issue, count in issue_counts.most_common():\n",
    "    print(f\"  {issue}: {count} files ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success = df[df['status'] == 'success']\n",
    "\n",
    "print(\"Overall Statistics:\")\n",
    "print(df_success[['snr_db', 'spectral_rolloff_hz', 'spectral_flatness', \n",
    "                   'zcr_mean', 'loudness_lufs']].describe())\n",
    "\n",
    "print(\"\\nPreprocessing Recommendations:\")\n",
    "all_recs = [rec for recs in df['recommended_preprocessing'] for rec in recs]\n",
    "rec_counts = Counter(all_recs)\n",
    "\n",
    "for rec, count in rec_counts.most_common():\n",
    "    print(f\"{rec:30s}: {count:4d} files ({count/len(df)*100:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"../data/audio_quality_analysis.parquet\")\n",
    "df.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"âœ“ Saved: {output_path}\")\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFile size: {output_path.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temp directory\n",
    "import shutil\n",
    "\n",
    "if TEMP_DIR.exists():\n",
    "    shutil.rmtree(TEMP_DIR)\n",
    "    print(f\"âœ“ Cleaned up temp directory: {TEMP_DIR}\")\n",
    "\n",
    "# Clear GPU memory\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"âœ“ Cleared GPU memory\")\n",
    "\n",
    "print(\"\\nâœ“ All done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
