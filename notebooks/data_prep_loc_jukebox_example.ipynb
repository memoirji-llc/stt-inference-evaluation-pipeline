{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: jukebox dataset\n",
    "import io\n",
    "import pandas as pd                     \n",
    "import requests\n",
    "from helpers_loc import get_file_stats\n",
    "DATA_URL = 'https://data.labs.loc.gov/jukebox/' # Base URL of this data package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting information from data package manifest...\")\n",
    "file_manifest_url = f'{DATA_URL}manifest.json'\n",
    "response = requests.get(file_manifest_url, timeout=60)\n",
    "response_json = response.json()\n",
    "# file information json\n",
    "files = [dict(zip(response_json[\"cols\"], row)) for row in response_json[\"rows\"]] # zip columns and rows\n",
    "stats = get_file_stats(files)\n",
    "print(\"Manifest: \" + str(stats))\n",
    "df_stats = pd.DataFrame(stats)\n",
    "print(\"Constructed manifest as df\")\n",
    "print(\"Columns: \" + ', '.join(df_stats.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting data package metadata\")\n",
    "metadata_url = f'{DATA_URL}metadata.json'\n",
    "response = requests.get(metadata_url, timeout=60)\n",
    "data = response.json()\n",
    "print(f'Loaded metadata file with {len(data):,} entries.')\n",
    "df_metadata = pd.DataFrame(data)\n",
    "print(\"Preview Dataframe:\")\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"explode df so that each row has one Subject only\")\n",
    "df_metadata_by_subject = df_metadata.explode('Subjects')\n",
    "print(\"example usage: calculate rows where subject = opera\")\n",
    "df_opera = df_metadata_by_subject[df_metadata_by_subject.Subjects == 'Opera']\n",
    "print(f'Found {df_opera.shape[0]:,} items with subject \"Opera\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from file information\n",
    "df_files = pd.DataFrame(files)\n",
    "# join the metadata dataframe with the file information dataframe\n",
    "opera_set_with_audio = pd.merge(df_opera, df_files, left_on='Id', right_on='item_id', how='inner')\n",
    "print(f'Found {opera_set_with_audio.shape[0]:,} rows with \"opera\" as subject with file information:')\n",
    "opera_set_with_audio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt         # for displaying data\n",
    "import numpy as np\n",
    "from pydub import AudioSegment          # for reading and manipulating audio files\n",
    "from scipy import signal                # for visualizing audio\n",
    "print(\"Constructing file url - First row as example\")\n",
    "# object_key contains the path to the audio file\n",
    "item = opera_set_with_audio.iloc[0]\n",
    "file_url = f'https://{item[\"object_key\"]}'\n",
    "print(\"file url: \" + file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting audio stream\")\n",
    "# Download the audio to memory\n",
    "response = requests.get(file_url, timeout=60)\n",
    "audio_filestream = io.BytesIO(response.content)\n",
    "# Read as mp3\n",
    "sample_rate = 48000\n",
    "sample_width = 1\n",
    "channels = 1\n",
    "audio_filestream.seek(0)  # Ensure stream is at the beginning\n",
    "sound = AudioSegment.from_mp3(audio_filestream)\n",
    "sound = sound.set_channels(channels)\n",
    "sound = sound.set_sample_width(sample_width)\n",
    "sound = sound.set_frame_rate(sample_rate)\n",
    "\n",
    "# Get the first 10 seconds\n",
    "ten_seconds = 10 * 1000\n",
    "first_10_seconds = sound[:ten_seconds]\n",
    "\n",
    "# Get audio samples and sample rate\n",
    "samples = first_10_seconds.get_array_of_samples()\n",
    "samples = np.array(samples)\n",
    "\n",
    "print(\"Visualize first 10 seconds of the audio stream:\")\n",
    "frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "plt.pcolormesh(times, frequencies, np.log(spectrogram))\n",
    "# plt.imshow(spectrogram)\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amia2025-stt-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
