{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Preprocessing Experiments\n",
    "\n",
    "**Goal:** Test different preprocessing techniques to improve STT accuracy on degraded archival audio.\n",
    "\n",
    "**Methods to test:**\n",
    "1. Baseline (no preprocessing)\n",
    "2. Noise reduction (spectral gating, Wiener filter)\n",
    "3. Loudness normalization (-23 to -18 LUFS)\n",
    "4. High-pass filtering (remove low-frequency rumble)\n",
    "5. Resampling (16kHz vs 48kHz)\n",
    "6. Combinations of above\n",
    "\n",
    "**Sample audio:** VHP audio (bandwidth-limited, low noise per previous analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "import pyloudnorm as pyln\n",
    "from scipy import signal\n",
    "import noisereduce as nr\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Audio\n",
    "\n",
    "Using VHP sample from previous quality analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio file\n",
    "audio_path = Path(\"../data/loc_veteran/sample_audio.mp3\")\n",
    "\n",
    "# Load with librosa (preserves original sample rate)\n",
    "y, sr = librosa.load(audio_path, sr=None, mono=True)\n",
    "\n",
    "print(f\"Sample rate: {sr} Hz\")\n",
    "print(f\"Duration: {len(y) / sr:.2f} seconds\")\n",
    "print(f\"Audio shape: {y.shape}\")\n",
    "\n",
    "# Display audio player\n",
    "print(\"\\nOriginal audio:\")\n",
    "display(Audio(y, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original waveform and spectrogram\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Waveform\n",
    "librosa.display.waveshow(y, sr=sr, ax=axes[0])\n",
    "axes[0].set_title(\"Original Waveform\")\n",
    "axes[0].set_xlabel(\"Time (s)\")\n",
    "axes[0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# Spectrogram\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "axes[1].set_title(\"Spectrogram (Original)\")\n",
    "axes[1].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "# Mel spectrogram\n",
    "M = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "M_db = librosa.power_to_db(M, ref=np.max)\n",
    "librosa.display.specshow(M_db, sr=sr, x_axis='time', y_axis='mel', ax=axes[2])\n",
    "axes[2].set_title(\"Mel Spectrogram (Original)\")\n",
    "axes[2].set_ylabel(\"Mel Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Audio Quality Metrics\n",
    "\n",
    "Measure the original audio quality before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_audio_metrics(y, sr):\n",
    "    \"\"\"\n",
    "    Calculate audio quality metrics.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Audio quality metrics\n",
    "    \"\"\"\n",
    "    # Spectral centroid (brightness)\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    centroid_mean = np.mean(centroid)\n",
    "    \n",
    "    # Spectral roll-off (bandwidth)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85)\n",
    "    rolloff_mean = np.mean(rolloff)\n",
    "    \n",
    "    # Spectral flatness (noise vs tonal)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    flatness_mean = np.mean(flatness)\n",
    "    \n",
    "    # Zero crossing rate (noisiness)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    \n",
    "    # RMS energy\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    rms_mean = np.mean(rms)\n",
    "    \n",
    "    # Loudness (LUFS) - using pyloudnorm\n",
    "    meter = pyln.Meter(sr)\n",
    "    loudness = meter.integrated_loudness(y)\n",
    "    \n",
    "    return {\n",
    "        'centroid_hz': centroid_mean,\n",
    "        'rolloff_hz': rolloff_mean,\n",
    "        'flatness': flatness_mean,\n",
    "        'zcr': zcr_mean,\n",
    "        'rms': rms_mean,\n",
    "        'loudness_lufs': loudness\n",
    "    }\n",
    "\n",
    "# Calculate baseline metrics\n",
    "baseline_metrics = calculate_audio_metrics(y, sr)\n",
    "\n",
    "print(\"Baseline Audio Quality Metrics:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in baseline_metrics.items():\n",
    "    print(f\"{key:20s}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Method 1: Noise Reduction\n",
    "\n",
    "Use spectral gating to remove background noise.\n",
    "\n",
    "**How it works:**\n",
    "- Analyzes noise profile from audio\n",
    "- Applies spectral gate to reduce noise below threshold\n",
    "- Preserves speech signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply noise reduction using noisereduce library\n",
    "# Method 1: Stationary noise reduction (spectral gating)\n",
    "y_reduced = nr.reduce_noise(y=y, sr=sr, stationary=True, prop_decrease=1.0)\n",
    "\n",
    "print(\"Noise reduction applied.\")\n",
    "print(\"\\nNoise-reduced audio:\")\n",
    "display(Audio(y_reduced, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize before/after noise reduction\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Original waveform\n",
    "librosa.display.waveshow(y, sr=sr, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Original Waveform\")\n",
    "axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# Noise-reduced waveform\n",
    "librosa.display.waveshow(y_reduced, sr=sr, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Noise-Reduced Waveform\")\n",
    "axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# Original spectrogram\n",
    "D_orig = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D_orig, sr=sr, x_axis='time', y_axis='hz', ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Original Spectrogram\")\n",
    "axes[1, 0].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "# Noise-reduced spectrogram\n",
    "D_reduced = librosa.amplitude_to_db(np.abs(librosa.stft(y_reduced)), ref=np.max)\n",
    "librosa.display.specshow(D_reduced, sr=sr, x_axis='time', y_axis='hz', ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Noise-Reduced Spectrogram\")\n",
    "axes[1, 1].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics\n",
    "noise_reduced_metrics = calculate_audio_metrics(y_reduced, sr)\n",
    "\n",
    "print(\"Metrics Comparison: Original vs Noise-Reduced\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<20} {'Original':>15} {'Noise-Reduced':>15} {'Change':>15}\")\n",
    "print(\"=\"*70)\n",
    "for key in baseline_metrics.keys():\n",
    "    orig = baseline_metrics[key]\n",
    "    reduced = noise_reduced_metrics[key]\n",
    "    change = ((reduced - orig) / orig * 100) if orig != 0 else 0\n",
    "    print(f\"{key:<20} {orig:>15.4f} {reduced:>15.4f} {change:>14.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Method 2: Loudness Normalization\n",
    "\n",
    "Normalize audio to target loudness (ITU-R BS.1770-4 standard).\n",
    "\n",
    "**Target:** -23 LUFS (broadcasting standard) to -18 LUFS (podcast standard)\n",
    "\n",
    "**Why:** Consistent loudness helps STT models (trained on normalized audio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loudness normalization\n",
    "def normalize_loudness(y, sr, target_lufs=-23.0):\n",
    "    \"\"\"\n",
    "    Normalize audio to target loudness (LUFS).\n",
    "    \n",
    "    Args:\n",
    "        y: Audio signal\n",
    "        sr: Sample rate\n",
    "        target_lufs: Target loudness in LUFS (default: -23.0 for broadcasting)\n",
    "    \n",
    "    Returns:\n",
    "        Normalized audio signal\n",
    "    \"\"\"\n",
    "    meter = pyln.Meter(sr)\n",
    "    loudness = meter.integrated_loudness(y)\n",
    "    \n",
    "    print(f\"Current loudness: {loudness:.2f} LUFS\")\n",
    "    print(f\"Target loudness: {target_lufs:.2f} LUFS\")\n",
    "    \n",
    "    # Normalize\n",
    "    y_normalized = pyln.normalize.loudness(y, loudness, target_lufs)\n",
    "    \n",
    "    # Verify\n",
    "    new_loudness = meter.integrated_loudness(y_normalized)\n",
    "    print(f\"New loudness: {new_loudness:.2f} LUFS\")\n",
    "    \n",
    "    return y_normalized\n",
    "\n",
    "# Test with -23 LUFS (broadcasting standard)\n",
    "print(\"Normalizing to -23 LUFS (broadcasting standard)...\")\n",
    "y_norm_23 = normalize_loudness(y, sr, target_lufs=-23.0)\n",
    "\n",
    "print(\"\\nLoudness-normalized audio (-23 LUFS):\")\n",
    "display(Audio(y_norm_23, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with -18 LUFS (podcast standard)\n",
    "print(\"Normalizing to -18 LUFS (podcast standard)...\")\n",
    "y_norm_18 = normalize_loudness(y, sr, target_lufs=-18.0)\n",
    "\n",
    "print(\"\\nLoudness-normalized audio (-18 LUFS):\")\n",
    "display(Audio(y_norm_18, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize waveforms: original vs normalized\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "librosa.display.waveshow(y, sr=sr, ax=axes[0])\n",
    "axes[0].set_title(f\"Original (Loudness: {baseline_metrics['loudness_lufs']:.2f} LUFS)\")\n",
    "axes[0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "librosa.display.waveshow(y_norm_23, sr=sr, ax=axes[1])\n",
    "axes[1].set_title(\"Normalized to -23 LUFS (Broadcasting Standard)\")\n",
    "axes[1].set_ylabel(\"Amplitude\")\n",
    "\n",
    "librosa.display.waveshow(y_norm_18, sr=sr, ax=axes[2])\n",
    "axes[2].set_title(\"Normalized to -18 LUFS (Podcast Standard)\")\n",
    "axes[2].set_ylabel(\"Amplitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing Method 3: High-Pass Filtering\n",
    "\n",
    "Remove low-frequency rumble (< 80 Hz) often present in analog recordings.\n",
    "\n",
    "**Why:** Low-frequency noise (rumble, hum) doesn't contribute to speech but can interfere with STT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-pass filter\n",
    "def highpass_filter(y, sr, cutoff_freq=80):\n",
    "    \"\"\"\n",
    "    Apply high-pass filter to remove low-frequency rumble.\n",
    "    \n",
    "    Args:\n",
    "        y: Audio signal\n",
    "        sr: Sample rate\n",
    "        cutoff_freq: Cutoff frequency in Hz (default: 80 Hz)\n",
    "    \n",
    "    Returns:\n",
    "        Filtered audio signal\n",
    "    \"\"\"\n",
    "    # Design Butterworth high-pass filter (4th order)\n",
    "    nyquist = sr / 2\n",
    "    normalized_cutoff = cutoff_freq / nyquist\n",
    "    \n",
    "    b, a = signal.butter(4, normalized_cutoff, btype='high', analog=False)\n",
    "    \n",
    "    # Apply filter\n",
    "    y_filtered = signal.filtfilt(b, a, y)\n",
    "    \n",
    "    print(f\"High-pass filter applied: cutoff = {cutoff_freq} Hz\")\n",
    "    \n",
    "    return y_filtered\n",
    "\n",
    "# Apply high-pass filter\n",
    "y_highpass = highpass_filter(y, sr, cutoff_freq=80)\n",
    "\n",
    "print(\"\\nHigh-pass filtered audio:\")\n",
    "display(Audio(y_highpass, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize frequency response\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Original waveform\n",
    "librosa.display.waveshow(y, sr=sr, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Original Waveform\")\n",
    "axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# High-pass filtered waveform\n",
    "librosa.display.waveshow(y_highpass, sr=sr, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"High-Pass Filtered Waveform\")\n",
    "axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# Original spectrum (low frequencies)\n",
    "D_orig = np.abs(librosa.stft(y))\n",
    "freqs_orig = librosa.fft_frequencies(sr=sr)\n",
    "low_freq_mask = freqs_orig < 500  # Focus on low frequencies\n",
    "axes[1, 0].plot(freqs_orig[low_freq_mask], np.mean(D_orig, axis=1)[low_freq_mask])\n",
    "axes[1, 0].set_title(\"Original Spectrum (0-500 Hz)\")\n",
    "axes[1, 0].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[1, 0].set_ylabel(\"Magnitude\")\n",
    "axes[1, 0].axvline(x=80, color='r', linestyle='--', label='Cutoff (80 Hz)')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# High-pass filtered spectrum (low frequencies)\n",
    "D_highpass = np.abs(librosa.stft(y_highpass))\n",
    "axes[1, 1].plot(freqs_orig[low_freq_mask], np.mean(D_highpass, axis=1)[low_freq_mask])\n",
    "axes[1, 1].set_title(\"High-Pass Filtered Spectrum (0-500 Hz)\")\n",
    "axes[1, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "axes[1, 1].set_ylabel(\"Magnitude\")\n",
    "axes[1, 1].axvline(x=80, color='r', linestyle='--', label='Cutoff (80 Hz)')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing Method 4: Resampling\n",
    "\n",
    "Test different sample rates for STT models.\n",
    "\n",
    "**Common rates:**\n",
    "- 16 kHz: Whisper, Wav2Vec2 preferred rate\n",
    "- 48 kHz: High-quality preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to 16 kHz (Whisper/Wav2Vec2 standard)\n",
    "y_16k = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "\n",
    "print(f\"Original sample rate: {sr} Hz\")\n",
    "print(f\"Resampled to: 16000 Hz\")\n",
    "print(f\"Original duration: {len(y) / sr:.2f} seconds\")\n",
    "print(f\"Resampled duration: {len(y_16k) / 16000:.2f} seconds\")\n",
    "\n",
    "print(\"\\nResampled audio (16 kHz):\")\n",
    "display(Audio(y_16k, rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spectrograms at different sample rates\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Original sample rate spectrogram\n",
    "D_orig = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D_orig, sr=sr, x_axis='time', y_axis='hz', ax=axes[0])\n",
    "axes[0].set_title(f\"Original Spectrogram ({sr} Hz)\")\n",
    "axes[0].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "# 16 kHz spectrogram\n",
    "D_16k = librosa.amplitude_to_db(np.abs(librosa.stft(y_16k)), ref=np.max)\n",
    "librosa.display.specshow(D_16k, sr=16000, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "axes[1].set_title(\"Resampled Spectrogram (16 kHz)\")\n",
    "axes[1].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combination Method: Full Preprocessing Pipeline\n",
    "\n",
    "Combine multiple preprocessing steps:\n",
    "1. High-pass filter (remove rumble)\n",
    "2. Noise reduction (remove background noise)\n",
    "3. Loudness normalization (consistent levels)\n",
    "4. Resample to 16 kHz (model input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_preprocessing_pipeline(y, sr, \n",
    "                                 highpass_cutoff=80, \n",
    "                                 noise_reduce=True,\n",
    "                                 target_lufs=-23.0,\n",
    "                                 target_sr=16000):\n",
    "    \"\"\"\n",
    "    Apply full preprocessing pipeline.\n",
    "    \n",
    "    Args:\n",
    "        y: Audio signal\n",
    "        sr: Sample rate\n",
    "        highpass_cutoff: High-pass filter cutoff frequency (Hz)\n",
    "        noise_reduce: Whether to apply noise reduction\n",
    "        target_lufs: Target loudness (LUFS)\n",
    "        target_sr: Target sample rate (Hz)\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed audio signal, new sample rate\n",
    "    \"\"\"\n",
    "    print(\"Starting preprocessing pipeline...\")\n",
    "    \n",
    "    # Step 1: High-pass filter\n",
    "    print(\"\\n[1/4] Applying high-pass filter...\")\n",
    "    y_proc = highpass_filter(y, sr, cutoff_freq=highpass_cutoff)\n",
    "    \n",
    "    # Step 2: Noise reduction\n",
    "    if noise_reduce:\n",
    "        print(\"\\n[2/4] Applying noise reduction...\")\n",
    "        y_proc = nr.reduce_noise(y=y_proc, sr=sr, stationary=True, prop_decrease=1.0)\n",
    "    else:\n",
    "        print(\"\\n[2/4] Skipping noise reduction\")\n",
    "    \n",
    "    # Step 3: Loudness normalization\n",
    "    print(\"\\n[3/4] Normalizing loudness...\")\n",
    "    y_proc = normalize_loudness(y_proc, sr, target_lufs=target_lufs)\n",
    "    \n",
    "    # Step 4: Resample\n",
    "    print(f\"\\n[4/4] Resampling to {target_sr} Hz...\")\n",
    "    if sr != target_sr:\n",
    "        y_proc = librosa.resample(y_proc, orig_sr=sr, target_sr=target_sr)\n",
    "        print(f\"Resampled: {sr} Hz → {target_sr} Hz\")\n",
    "    else:\n",
    "        print(f\"Already at {target_sr} Hz, skipping resample\")\n",
    "    \n",
    "    print(\"\\nPreprocessing pipeline complete!\")\n",
    "    return y_proc, target_sr\n",
    "\n",
    "# Apply full pipeline\n",
    "y_full_preproc, sr_full_preproc = full_preprocessing_pipeline(\n",
    "    y, sr,\n",
    "    highpass_cutoff=80,\n",
    "    noise_reduce=True,\n",
    "    target_lufs=-23.0,\n",
    "    target_sr=16000\n",
    ")\n",
    "\n",
    "print(\"\\nFully preprocessed audio:\")\n",
    "display(Audio(y_full_preproc, rate=sr_full_preproc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison: original vs fully preprocessed\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Original waveform\n",
    "librosa.display.waveshow(y, sr=sr, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Original Waveform\")\n",
    "axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# Preprocessed waveform\n",
    "librosa.display.waveshow(y_full_preproc, sr=sr_full_preproc, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Fully Preprocessed Waveform\")\n",
    "axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# Original spectrogram\n",
    "D_orig = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "librosa.display.specshow(D_orig, sr=sr, x_axis='time', y_axis='hz', ax=axes[1, 0])\n",
    "axes[1, 0].set_title(f\"Original Spectrogram ({sr} Hz)\")\n",
    "axes[1, 0].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "# Preprocessed spectrogram\n",
    "D_preproc = librosa.amplitude_to_db(np.abs(librosa.stft(y_full_preproc)), ref=np.max)\n",
    "librosa.display.specshow(D_preproc, sr=sr_full_preproc, x_axis='time', y_axis='hz', ax=axes[1, 1])\n",
    "axes[1, 1].set_title(f\"Preprocessed Spectrogram ({sr_full_preproc} Hz)\")\n",
    "axes[1, 1].set_ylabel(\"Frequency (Hz)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Preprocessed Audio Files\n",
    "\n",
    "Save different preprocessing variants for testing with STT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../data/preprocessed_samples\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save variants\n",
    "variants = {\n",
    "    \"baseline\": (y, sr),\n",
    "    \"noise_reduced\": (y_reduced, sr),\n",
    "    \"loudness_norm_23lufs\": (y_norm_23, sr),\n",
    "    \"loudness_norm_18lufs\": (y_norm_18, sr),\n",
    "    \"highpass_filtered\": (y_highpass, sr),\n",
    "    \"resampled_16khz\": (y_16k, 16000),\n",
    "    \"full_pipeline\": (y_full_preproc, sr_full_preproc)\n",
    "}\n",
    "\n",
    "for variant_name, (audio, sample_rate) in variants.items():\n",
    "    output_path = output_dir / f\"sample_{variant_name}.wav\"\n",
    "    sf.write(output_path, audio, sample_rate)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "print(f\"\\nAll variants saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "**Preprocessing methods tested:**\n",
    "1. ✅ Noise reduction (spectral gating)\n",
    "2. ✅ Loudness normalization (-23 LUFS, -18 LUFS)\n",
    "3. ✅ High-pass filtering (80 Hz cutoff)\n",
    "4. ✅ Resampling (16 kHz)\n",
    "5. ✅ Full pipeline (combination of all)\n",
    "\n",
    "**Next steps:**\n",
    "1. Create `preprocess_audio.py` script based on notebook code\n",
    "2. Test script locally on VHP samples\n",
    "3. Run preprocessing on cloud for full dataset\n",
    "4. Run STT inference on preprocessed variants\n",
    "5. Compare WER across preprocessing methods\n",
    "\n",
    "**Key insights for script design:**\n",
    "- Need command-line args for preprocessing method selection\n",
    "- Config YAML for parameterization (cutoff frequencies, target LUFS, etc.)\n",
    "- Azure Blob integration for input/output\n",
    "- Parallel processing support for batch operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amia2025-stt-benchmarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
