# Experiment: Whisper large-v3, ALL files (~4600), 5 minutes each (GPU)
# Complete dataset benchmark with large model - NO SAMPLING
# WARNING: This will take MANY hours to complete (estimate: 12-24 hours)!

experiment_id: vhp-large-v3-300s-gpu
model:
  name: "whisper-large-v3"
  dir: "./models/faster-whisper/models--Systran--faster-whisper-large-v3"
  batch_size: 8  # Smaller batch for larger model
  device: "cuda"
  compute_type: "float16"

input:
  source: "azure_blob"
  parquet_path: "data/raw/loc/veterans_history_project_resources.parquet"
  blob_prefix: "loc_vhp"
  sample_size: null  # Process ALL files (no sampling)
  duration_sec: 300  # 5 minutes
  sample_rate: 16000

output:
  dir: "outputs/vhp-large-v3-300s-gpu"
  save_per_file: true

wandb:
  project: amia-stt
  group: experiments-gpu-full-dataset
  tags: ["whisper-large-v3", "all-files", "duration-300s", "gpu", "t4", "complete-benchmark"]
