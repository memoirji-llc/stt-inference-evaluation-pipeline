# Experiment: GCP Chirp 3, ALL pre-2010 files, full duration (GPU inference-only)
# Complete dataset benchmark - NO SAMPLING, NO EVALUATION
# This will only generate transcripts (inference_results.parquet + hypothesis files)

experiment_id: vhp-pre2010-chirp3-full-gpu

model:
  name: "gcp_chirp"
  model_variant: "chirp_3"  # Options: "chirp" (Chirp 2), "chirp_2" (Chirp 2), "chirp_3" (Chirp 3)

  # GCP-specific settings
  gcp:
    project_id: "memoirji-amia-2025"
    credentials_path: "credentials/gcloud/application_default_credentials.json"
    temp_bucket: "memoirji-amia-2025-temp"

    # Parallelization settings (moderate for large batch)
    upload_workers: 50
    transcribe_workers: 20
    batch_size: 100

    # API settings
    language_code: "en-US"
    upload_timeout: 600  # Upload timeout in seconds (10 minutes for large files)
    transcribe_timeout: 14400  # Transcription timeout in seconds (4 hours - GCP supports up to 8hr audio)

input:
  source: "azure_blob"
  parquet_path: "data/raw/loc/veterans_history_project_resources_pre2010.parquet"
  blob_prefix: "loc_vhp"
  sample_size: null  # Process ALL files (no sampling)
  duration_sec: null  # Full audio
  sample_rate: 16000

output:
  dir: "outputs/vhp-pre2010-chirp3-full-gpu"
  save_per_file: true  # Save individual hyp_{id}.txt files

# NOTE: No evaluation section - run inference only
# To evaluate later, use: uv run python scripts/evaluate.py --config <this-file> --inference_results <output>/inference_results.parquet --parquet <path-to-parquet>

wandb:
  project: amia-stt
  group: experiments-commercial-api-full
  tags: ["gcp-chirp3", "pre2010", "all-files", "full-duration", "commercial-api", "inference-only"]