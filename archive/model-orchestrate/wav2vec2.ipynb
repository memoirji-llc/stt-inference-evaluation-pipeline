{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a0f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n",
      "2.7.1\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51ff7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('video', '/Volumes/KINGSTON/veteran_interviews/0/video.mp4')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "MEDIA_DIR = \"/Volumes/KINGSTON/veteran_interviews\"\n",
    "# index = 0\n",
    "# audio_path = f\"{MEDIA_DIR}/{index}/audio.mp3\"\n",
    "# video_path = f\"{MEDIA_DIR}/{index}/video.mp4\"\n",
    "# # check if the audio file exists\n",
    "# if not os.path.exists(audio_path):\n",
    "#     raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "# # check if the video file exists\n",
    "# if not os.path.exists(video_path):\n",
    "#     raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "\n",
    "# develop a function to return media type, and audio/ video path based on index\n",
    "def get_media_type_and_path(index):\n",
    "    audio_path = f\"{MEDIA_DIR}/{index}/audio.mp3\"\n",
    "    video_path = f\"{MEDIA_DIR}/{index}/video.mp4\"\n",
    "    if os.path.exists(video_path):\n",
    "        return \"video\", video_path\n",
    "    elif os.path.exists(audio_path):\n",
    "        return \"audio\", audio_path\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "get_media_type_and_path(0)  # Test the function with index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef272ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parquet file\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"../datasets/veterans_history_project_resources.parquet\")\n",
    "df['media_type'] = df.index.to_series().apply(lambda x: get_media_type_and_path(x)[0] if get_media_type_and_path(x) else None)\n",
    "df['media_filepath'] = df.index.to_series().apply(lambda x: get_media_type_and_path(x)[1] if get_media_type_and_path(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbad3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample dataset of 100 rows where returned media type is audio\n",
    "df_sample = df[df['media_type'] == 'audio'].sample(n=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9911b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "# testing_raw_transcript = df_sample['fulltext_file_str'][730]\n",
    "# strip content from the xml (only get the text between <p> tags)\n",
    "import re\n",
    "def strip_xml_tags(text):\n",
    "    # make sure the input is a string\n",
    "    if not isinstance(text, str):\n",
    "        # force it to be a string\n",
    "        text = str(text)\n",
    "    # Remove all XML tags except <p> and <speaker>\n",
    "    # Find the position of the first <speaker> tag\n",
    "    speaker_match = re.search(r'<speaker>.*?</speaker>', text, re.DOTALL)\n",
    "    if not speaker_match:\n",
    "        return \"\"\n",
    "    start_pos = speaker_match.end()\n",
    "    # Only search for <p>...</p> after the first <speaker>\n",
    "    paragraphs = re.findall(r'<p>(.*?)</p>', text[start_pos:], re.DOTALL)\n",
    "    # Remove everything after \"[Conclusion of Interview]\"\n",
    "    result = []\n",
    "    for para in paragraphs:\n",
    "        if \"[Conclusion of Interview]\" in para:\n",
    "            break\n",
    "        result.append(para)\n",
    "    return '\\n'.join(result)\n",
    "# testing_raw_transcript_stripped = strip_xml_tags(testing_raw_transcript)\n",
    "# apply this function to the fulltext_file_str column\n",
    "df_sample['raw_transcript_stripped'] = df_sample['fulltext_file_str'].apply(strip_xml_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b13b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730     Joe, give us the basic identifying information...\n",
       "1278    Good morning. Today is January 14, 2012. My na...\n",
       "3545    This is Ashley Hancher interviewing Thomas Mar...\n",
       "3691    It's Monday, May 31, 2014, Memorial Day. We ar...\n",
       "1176    Hi. My name is Megan Schwartz. Today is Januar...\n",
       "4199    Every morning I went by the path that went int...\n",
       "5409    Oral History interview of World War II Veteran...\n",
       "3601    The interview is being conducted for the Veter...\n",
       "3418    This tape, it is July, 2003. My name is Julie ...\n",
       "3417    My name is Steve Estes and today is August 9, ...\n",
       "Name: raw_transcript_stripped, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['raw_transcript_stripped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6475820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730     /Volumes/KINGSTON/veteran_interviews/730/audio...\n",
       "1278    /Volumes/KINGSTON/veteran_interviews/1278/audi...\n",
       "3545    /Volumes/KINGSTON/veteran_interviews/3545/audi...\n",
       "3691    /Volumes/KINGSTON/veteran_interviews/3691/audi...\n",
       "1176    /Volumes/KINGSTON/veteran_interviews/1176/audi...\n",
       "4199    /Volumes/KINGSTON/veteran_interviews/4199/audi...\n",
       "5409    /Volumes/KINGSTON/veteran_interviews/5409/audi...\n",
       "3601    /Volumes/KINGSTON/veteran_interviews/3601/audi...\n",
       "3418    /Volumes/KINGSTON/veteran_interviews/3418/audi...\n",
       "3417    /Volumes/KINGSTON/veteran_interviews/3417/audi...\n",
       "Name: media_filepath, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['media_filepath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff17d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sample dataset to a new parquet file\n",
    "df_sample.to_parquet(\"../datasets/veterans_history_project_sample.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a39229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ac/main/broken-record/model_train/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 10 examples [00:00, 1479.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# load parquet file as a Hugging Face dataset\n",
    "hf_dataset = load_dataset('parquet', data_files=\"../datasets/veterans_history_project_sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6821bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc695c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "def preprocess_audio(file_path):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "    return waveform\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = preprocess_audio(batch[\"media_filepath\"])\n",
    "    batch[\"input_values\"] = processor(audio, sampling_rate=16000).input_values[0]\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"raw_transcript_stripped\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31d4a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [08:35<00:00, 51.51s/ examples]\n"
     ]
    }
   ],
   "source": [
    "dataset = hf_dataset.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7cd9328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (8/8 shards): 100%|██████████| 10/10 [00:12<00:00,  1.21s/ examples]\n"
     ]
    }
   ],
   "source": [
    "# save dataset to disk\n",
    "dataset.save_to_disk(\"../datasets/veterans_history_project_sample_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a04e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ac/main/broken-record/model_train/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# retrieve the dataset from disk\n",
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"../datasets/veterans_history_project_sample_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25794124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Split 90% train, 10% validation\n",
    "split_dataset = dataset['train'].train_test_split(test_size=0.1)\n",
    "\n",
    "# Rename 'test' split to 'validation'\n",
    "split_dataset = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'validation': split_dataset['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777a82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc198dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/rhwrg1yd1vq5gr2f0q6b0ngw0000gn/T/ipykernel_6335/790459817.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import accelerate\n",
    "reload(accelerate)\n",
    "# reload(TrainingArguments)\n",
    "# reload(Trainer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    per_device_train_batch_size=1,\n",
    "    eval_strategy=\"no\",\n",
    "    num_train_epochs=2,\n",
    "    fp16=False,\n",
    "    save_strategy=\"no\",\n",
    "    dataloader_num_workers=0,\n",
    "    logging_steps=10,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"validation\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8a998f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())  # Should be True\n",
    "print(torch.backends.mps.is_built())       # Should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63efe74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ac/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/transformers/trainer.py:2509\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2507\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2508\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2509\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2511\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/transformers/trainer.py:5263\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5262\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5263\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5264\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5265\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/accelerate/data_loader.py:567\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:2781\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2781\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2782\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:2777\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2761\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2762\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:653\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    651\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:410\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:466\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 466\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:149\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85aebb",
   "metadata": {},
   "source": [
    "END for HF train here^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7906d659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/rhwrg1yd1vq5gr2f0q6b0ngw0000gn/T/ipykernel_66580/3117175126.py:1: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "torchaudio.set_audio_backend(\"soundfile\")\n",
    "# Load and resample audio\n",
    "waveform, sample_rate = torchaudio.load(wav_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf0a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a7751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.1479e-05,\n",
       "         -5.2398e-05,  2.4214e-06]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f1b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 10404 examples [00:01, 6927.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "parentNaId = \"653144\"\n",
    "filepath = f'../datasets/{parentNaId}_transcriptions_with_audio.parquet'\n",
    "filepath = f'../datasets/veterans_history_project_resources.parquet'\n",
    "# Load dataset from CSV\n",
    "dataset = load_dataset('parquet', data_files=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0500858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['collection_number', 'fulltext_file_url', 'fulltext_file_str', 'video_url', 'audio_url', 'title', 'description', 'dates', 'language', 'location', 'location_home', 'location_service', 'partof', 'subject', 'subject_battles', 'subject_branch', 'subject_conflict', 'subject_entrance', 'subject_format', 'subject_gender', 'subject_rank', 'subject_status', 'subject_unit', 'subject_race'],\n",
       "        num_rows: 10404\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76312033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 26.32 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 16.90 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:03<00:00,  1.86s/ examples]\n"
     ]
    }
   ],
   "source": [
    "dataset[\"train\"][0]['audio_filepaths'][0]\n",
    "# create new column to store the filepath after conversion\n",
    "# audio_filepaths are lists, only take the first element for conversion\n",
    "dataset = dataset.map(lambda x: {'audio_filepath_1st': [fp[0].replace(\"./\", \"../datasets/\") for fp in x['audio_filepaths']]}, batched=True)\n",
    "dataset = dataset.map(lambda x: {'transcription_str': [next(iter(t.values()))['transcription'] for t in x['transcription']]}, batched=True)\n",
    "dataset = dataset.map(lambda x: {'audio_filepath_1st': [convert_mp3_to_wav(fp) for fp in x['audio_filepath_1st']]}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c42bfb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/audio/208-192.wav'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]['audio_filepath_1st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36209ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Announcer: Good evening from the White House in Washington. Ladies and Gentlemen, the President of the United States. \\n\\nTruman: Fellow citizens. On August the 18th, 1945, four days after the surrender of Japan, I issued Executive Order 9599 which laid down the guiding policies of your government during the transition from war to peace. Briefly stated these policies are: First, to assist in the maximum production of civilian goods. Second, as rapidly as possible to remove Government controls and restore collective bargaining and free markets. Third, to avoid both inflation and deflation. Those are still our policies. One of the major factors determining whether or not we shall succeed in carrying out those policies is the question of wages and prices. If wages go down substantially, we face deflation. If prices go up substantially, we face inflation. We must be on our guard, and steer clear of both these dangers to our security.\\n\\nWhat happens to wages is important to all of us, even to those of us who do not work for wages. It is important to business, for example, not only because wages represent an essential item in the cost of producing goods, but because people cannot buy the products of industry unless they earn enough wages generally. What happens to wages is also important to the farmer. The income he earns depends a great deal on the wages and purchasing power of the workers in our factories and shops and stores. They are the customers of the farmer and cannot buy farm products unless they earn enough wages. The fact is that all of us are deeply concerned with wages, because all of us are concerned with the well-being of all parts of our economic system. That is a simple truth. But like all simple truths, it is too often forgotten. Management sometimes forgets that business cannot prosper without customers who make good wages and have money in their pockets. Labor sometimes forgets that workers cannot find employment and that wages cannot rise unless business prospers and makes profits.\\n\\nLike most of you, I have been disturbed by the labor difficulties of recent weeks. These difficulties stand in the way of reconversion. They postpone the day when our veterans and displaced war workers can get back into good peacetime jobs. We need more of the good sense, the reasonableness, the consideration for the position of the other fellow, the teamwork which we had during the war. It has been my experience in public life that there are few problems which cannot be worked out, if we make a real effort to understand the other fellow\\'s point of view, and if we try to find a solution on the basis of give-and-take, of fairness to both sides. I want to discuss the wage problem in just that spirit, and I hope that all of us in the United States can start thinking about it that way.\\n\\nLet me begin by putting labor\\'s position before you. I do not think all of us understand how hard a blow our industrial workers have suffered in the shift from war production to peace production. You do know that sudden total victory caused millions of war workers to be laid off with very short notice or none at all. While we hope to overcome that condition before too many months have passed, unemployment is hardly a suitable reward for the contribution which veterans and war workers have made to victory.\\n\\nSeveral months ago, I urged the Congress to amend the unemployment compensation law so as to help workers through the difficult months of unemployment until reconversion could be affected. The Congress has not yet passed that legislation. The responsibility for that is solely up to Congress, and specifically, I mean the Ways and Means Committee of the House of Representatives. I hope that this Committee will fulfill its obligation to the people of the Nation and will give the Members of the House an early chance to vote on this important legislation. We must all recognize that legislation will help sustain the purchasing power of labor until reconversion is completed. [It] benefits not labor alone but all of us: business, agriculture, white-collar workers, and every member of our economic society. \\n\\nI am sure that the workers of the Nation, those who depend upon manual labor for a livelihood, also feel a deep concern about full employment legislation which is now pending in the Congress. It is essential that the Congress speedily adopt some effective legislation which embodies the principles underlying full employment. The American people are entitled to know now that this Government stands for prosperity and jobs, not depression and relief. Passage of a full employment bill will give the American people this assurance. The responsibility for the damaging delay in enacting this legislation is definitely at the door of the Committee on Expenditures in the Executive Departments of the House of Representatives.\\n\\nI am also sure that the workers of the Nation feel the same way about what is now happening to the United States Employment Service in the Senate and in the House. During the next year, millions of workers will have to look to efficient and centralized employment offices to find jobs for them anywhere in the country. The United States Employment Service has done so much during the war, and can do so much during the months ahead if it can continue to operate as a nationwide and unified organization, that I hope the Congress, for the time being, will keep this great public service under Federal management.\\n\\nBut quite as important as these problems of unemployment is the fact that the end of the war has meant a deep cut in the pay envelopes of many millions of workers. I wonder how many of you know that many war workers have already had to take, or will soon have to take, a cut in their wartime pay by one quarter or more. Think of what such a decrease in your own income would mean to you and to your families. How does it happen that pay envelopes are being cut so deeply ? There are three reasons.\\n\\nFirst, there is the present decrease in the number of hours of employment. During the past few years of war, millions of workers were asked to put in abnormally long hours of work. Now that the need is past, the forty-hour week is being restored. A changeover from a forty-eight to a forty-hour week means a decrease in take-home pay, the amount in the pay envelope. That decrease is much more than just the loss of eight hours pay. Workers have been receiving time and a half for overtime for all the hours they worked over forty hours. That overtime pay is now gone in the change to a forty-hour week. The result has been a decrease of almost one quarter in the workers\\' weekly pay. Second, weekly pay is being cut because many jobs are being reclassified to lower paying grades. The individual worker will feel these particularly when he changes from one job to another, starting at the bottom of the grade. Third, the pay envelopes of workers will be thinner because millions of workers who were employed in the highly paid war industries will now have to find jobs in lower-wage, peacetime employment. These three factors, added together, mean a drastic cut in the take home pay of millions of workers. If nothing is done to help the workers in this situation, millions of families will have to tighten their belts, and by several notches. It has been estimated that, unless checked, the annual wage and salary bill in private industry will shrink by over twenty billions of dollars. That is not going to do anybody any good: labor, business, agriculture, or the general public. The corner grocer is going to feel it, just as well as the department store, the railroads, the theaters, and the gas stations, and all the farmers of the Nation. It is a sure road to wide unemployment.\\n\\nThis is what is known as deflation, and it is just as dangerous as inflation. However, we must understand that we cannot hope, with a reduced work week, to maintain now the same take-home pay for labor generally that it has had during the war. There will have to be a drop. But the Nation cannot afford to have that drop too drastic. Wage increases are therefore imperative to cushion the shock to our workers, to sustain adequate purchasing power and to raise the national income.\\n\\nThere are many people who have said to me that industry cannot afford to grant any wage increases, without obtaining a corresponding increase in the price of its products. And they have urged me to use the machinery of Government to raise both. This proposal cannot be accepted under any circumstances. To accept it would mean but one thing, inflation. And that invites disaster. An increase in wages, if it were accompanied by an increase in the cost of living, would not help even the workers themselves. Every dollar that would be put in their pay envelopes under those circumstances, would be needed to meet the higher living expenses resulting from increased prices. Obviously, such a juggling of wages and prices would not settle anything or satisfy anyone. A runaway inflation would be upon us. When inflation comes and the cost of living begins to spiral, nearly everybody suffers. Wage increases, under those conditions, would defeat their own purpose and mean nothing to labor. White-collar workers would find that their fixed salaries buy less food and clothing than before. Farmers\\' incomes would shrink because they would have to pay so much more for what they buy. Increased earnings would mean nothing to business itself. War bonds, insurance policies, pensions, annuities, bonds of all kinds would shrink in value, and their incomes would dwindle in buying power.\\n\\nTherefore, wherever price increases would have inflationary tendencies, we must above all else, hold the line on prices. Let us hold vigorously to our defense against inflation. Let us continue to hold the price line as we have held it since the spring of 1943. If we depart from this program of vigorous and successful price control, if we now begin to let down the bars, there will be no stopping place. After the last war this Nation was confronted by much the same problem. At that time, we simply pulled off the few controls that had been established and let nature take its course. The result should stand as a lesson to all of us. A dizzy upward spiral of wages and the cost of living ended in the crash of 1920; a crash that spread bankruptcy and foreclosure and unemployment throughout the Nation. If these twin objectives of ours, stability of prices and higher wage rates were irreconcilable, if one could not be achieved without sacrificing the other, the outlook for all of us, labor, management, the farmer, and the consumer, would be very black indeed.\\n\\nFortunately, this is not so. While the positions of different industries vary greatly, there is room in the existing price structure for business as a whole to grant increases in wage rates. And if all of us would approach the problem in a spirit of reasonableness and give-and-take; if we would sit down together and try to determine how much increase particular companies or industries could allow at a particular time, I think most businessmen would agree that wage increases are possible. Many of them, in fact, have already negotiated substantial wage increases without asking for any increase of prices.\\n\\nThere are several reasons why I believe that industry as a whole can afford substantial wage increases without raising prices. First, the elimination of the time and a half for overtime has reduced labor costs per hour. Second, the increase in the number of people needing jobs is resulting in a downward reclassification of jobs in many industries and in many sections of the country. There is a third reason for believing that business can afford to pay wage increases, namely, increased output per hour of work or what is generally called increased productivity. While increased production rests ultimately with labor, the time will soon come when improvements in machinery and manufacturing know-how developed in the war can certainly result in more goods per hour and additional room for wage increases. As a fourth reason, business is in a very favorable profit position today, with excellent prospects for the period that lies ahead. Again, that is not true of all companies. Nevertheless, throughout industry and in every branch of industry, profits have been and still are very good indeed. Finally, the Congress at my suggestion, is now considering the elimination of the excess profits tax. Provision has already been made in our tax laws to enable corporations whose earnings dropped below their normal peacetime level to recapture a high proportion of the excess profits taxes which they have paid during the preceding two years. These and other provisions of the tax laws were designed to reduce to a minimum the risks entailed in reconversion and that is precisely what they accomplish. They also add to the ability of industry to increase wages.\\n\\nThere are, however, important limits upon the capacity of industry to raise wages without raising prices. Let me put industry\\'s position before you. Industry has many risks and problems ahead that labor must recognize. For many companies, wartime products which were very profitable will have to be replaced by civilian products which will not be so profitable.\\n\\nThere are also problems of reconverting plants, of developing new sources of supply, new products, and new markets, of training inexperienced workers, of meeting increased costs of raw materials and supplies. All these will mean, at the beginning, lower volume and higher unit costs. These problems and difficulties are particularly true in the case of small business, which is the backbone of the American competitive system.\\n\\nI have said that not all companies can afford these wage increases. I want to make clear, further, that there are companies where wages and even overtime pay continue high and where no suffering will be caused to the workers during reconversion. Labor must recognize these differences and not demand more than an industry or a company can pay under existing prices and conditions. It has a stern responsibility to see that demands for wage increases are reasonable. Excessive demands would deny to industry reasonable profits to which it is entitled and which are necessary to stimulate an expansion of production. We must not kill the goose which lays the golden egg. Labor itself has a responsibility to aid industry in reaching this goal of higher production and more jobs. It must strive constantly for greater efficiency and greater productivity; good work done, for good wages earned. Only in that way, can we reach the mass production that has brought this country to the front of the industrial countries of the world. Labor must constantly find ways within its own ranks of cutting down on absenteeism, reducing turn-over, avoiding jurisdictional disputes and \"wildcat\" strikes. Labor and management must adopt collective bargaining as the effective and mature way of doing business.\\n\\nThe extent to which industry can grant wage increases without price increases will vary from company to company and from industry to industry. What can be paid today when we are on the threshold of our postwar production will be different from what can be paid next year and the year after, when markets have been established and earnings have become apparent. Both management and labor must keep on exploring these developments and determine from time to time to what extent costs have been reduced and profits have been increased, and how far these can properly be passed on in the form of increased wages.\\n\\nLet me now turn to the question of just how wages are to be increased. Many people have asked the Government to step in and decide who is to increase wages and by exactly how much. I have, indeed, been criticized because I have not stepped in to lay down the law to business and labor. My refusal to do so has been deliberate. Curiously enough, the same people who urge me to use Government wartime machinery of control to determine wage adjustments have on other occasions been the first to point out that the continued intervention of Government must spell the end of our system of free enterprise. I am convinced that we must get away as quickly as possible from Government controls, and that we must get back to the free operation of our competitive system. Where wages are concerned, this means that we must get back to free and fair collective bargaining.\\n\\nAs a free people, we must have the good sense to bargain peaceably and sincerely. We must be determined to reach decisions based upon our long-range interest. Let me emphasize, however, that the decisions that are reached in collective bargaining must be kept within the limits laid down by the wage-price policy of the Government. This policy was described in the order of last August which I have already mentioned. Briefly, it allows management to make wage increases without Government approval but requires Government approval before the wage increase can be reflected in higher price ceilings. That is still the policy of the United States. To guide labor and management in their interpretation of this Executive order, I have today issued an amendment which I hope every one of you will read carefully in your newspapers tomorrow, amplifying the order and setting forth three classes of cases in which wage increases may be granted even though price ceiling increases may result. They are all situations where wage increases are necessary, irrespective of price consequences. They will not cause many price increases.\\n\\nIn addition, the amendment makes two points of importance which I wish to emphasize here. The first point has been true all along, but it has not been generally understood. If management does grant a wage increase, it is not prevented from coming in thereafter and requesting Government approval to have the wage increase considered for purposes of increasing prices. Whether such approval is sought before or after the wage increase is given, it receives the same consideration. The second point is new and is very important. It is something which I am sure will help industry get over this very difficult period of readjustment. In cases where no approval of the wage increase has been requested by management, or even where a request has been made denied by the Government, industry will not be asked by the Government to take an unreasonable chance in absorbing such wage increases. After a reasonable test period which, save in exceptional cases, will be six months, if the industry has been unable to produce at a fair profit, the entire wage increase will be taken into account in passing upon applications for price ceiling increases. The Office of Price Administration will have to give its prompt consideration to all applications for price increases.\\n\\nThis is your Government\\'s wage-price policy. For the time being, the machinery that administers it will remain the same as during the War. But, as you know, I have called a conference here in Washington of the representatives of management and labor. It will start next week. One of their jobs is to recommend machinery for mediating or arbitrating differences wherever collective bargaining fails to work. I hope the American people recognize how vital this conference actually is. Out of it can come the means of achieving industrial harmony and a new approach to human relationships in industry. Until that machinery can be worked out, I urge upon labor and upon management the necessity of getting together on their problems. Public opinion will not countenance a refusal on the part of either management or labor to proceed in a peaceful, free, and democratic manner to arrive at just conclusions.\\n\\nThis is a time for proving the lessons we have learned during the war; the lessons of fair play, of give-and-take on a democratic basis, of working together in unity for the future. We all have a common aim, which is prosperity and security, and a just share of the good things of life. We can help attain this aim if we sit down at the conference table and iron out our troubles together. There is no room in our economy for unfair dealing or for greedy individuals, or groups on either side, who want their own way regardless of the cost to others. The people will not stand for it. Their Government will not stand for it. The country is entitled to expect that industry and labor will bargain in good faith, with labor recognizing the right of industry to a fair profit and industry recognizing labor\\'s need to a decent and sustained standard of living, and with both of them realizing that we cannot have either deflation or inflation in our economy. The country, on the other hand, should be patient and realize that many of the parties are out of practice in collective bargaining. The point at which the people of the country are entitled to become impatient and to consider the need of Government action, is when one of the parties fails to bargain in good faith or refuses a reasonable offer of conciliation or arbitration.\\n\\nI know that this is not an easy way to solve the wage problem, but it is the sound way. It is the American way. I am convinced that if labor and management will approach each other with the realization that they have a common goal, and with the determination to compose their differences in their own long-range interest, it will not be long before we have put industrial strife behind us. Labor is the best customer management has and management is the source of labor\\'s livelihood. Both are wholly dependent on each other and the country in turn is dependent upon both of them. Americans have always responded well in times of national need. There are no easy answers, there is no simple formula for solving our difficult problems.\\n\\nI have boundless faith in the commonsense and ultimate fairness of the American people. Given unity of purpose and a determination to meet the challenge of the times, there is nothing too difficult for them to accomplish. They have performed miracles during the war. They can, they will, surmount the difficulties which face them now on their road to continued peace and well-being.\\n\\nAnnouncer: Ladies and Gentlemen, you have just heard the President of the United States. And now our National Anthem. \\n\\n(music)\\n\\n\\n                                                                                                                   -0-'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]['transcription_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b59564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/2 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 19.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "\n",
    "def preprocess_text(batch):\n",
    "    batch[\"input_ids\"] = tokenizer(batch[\"transcription_str\"], padding=True, truncation=True).input_ids\n",
    "    return batch\n",
    "\n",
    "    # Convert tokenized output to a numpy array to ensure consistent dtype\n",
    "    tokenized = tokenizer(texts, padding=True, truncation=True, return_tensors='np')\n",
    "    batch[\"input_ids\"] = tokenized[\"input_ids\"].tolist()\n",
    "    batch[\"attention_mask\"] = tokenized[\"attention_mask\"].tolist()\n",
    "    return batch\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset = dataset.map(preprocess_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcec55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/Users/ac/main/broken-record/model_train/.venv/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef489349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model configuration for new vocabulary size\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56eda7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6b22a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a custom collator\n",
    "def data_collator(batch):\n",
    "    audio_features = [item[\"input_values\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    return {\"input_values\": audio_features, \"labels\": labels}\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset, batch_size=16, shuffle=False, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6392d8f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[78], line 5\u001b[0m, in \u001b[0;36mdata_collator\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata_collator\u001b[39m(batch):\n\u001b[0;32m----> 5\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio_features, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels}\n",
      "Cell \u001b[0;32mIn[78], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata_collator\u001b[39m(batch):\n\u001b[0;32m----> 5\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m [\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio_features, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_values'"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd0c413d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_index', '_id', '_score', '_source', 'sort', 'hit_title', 'hit_record_urls', 'hit_digitalObjects_metadata', 'transcription', 'audio_filepaths', 'audio_filepath_1st', 'transcription_str', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6c9493f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Use \"input_ids\" as both input and label, to avoid KeyError\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m         labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/main/broken-record/model_train/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[78], line 5\u001b[0m, in \u001b[0;36mdata_collator\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata_collator\u001b[39m(batch):\n\u001b[0;32m----> 5\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio_features, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels}\n",
      "Cell \u001b[0;32mIn[78], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata_collator\u001b[39m(batch):\n\u001b[0;32m----> 5\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m [\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      6\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio_features, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_values'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Define optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        # Use \"input_ids\" as both input and label, to avoid KeyError\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"input_ids\"]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed with loss {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
